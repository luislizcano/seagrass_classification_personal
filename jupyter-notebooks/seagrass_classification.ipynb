{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automated Seagrass Classification Using Earth Engine Python API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script classify seagrass beds in selected BOA images using ground-data to train three machine learning classifiers: CART, Support Vector Machine and Random Forest. The outputs can be exported to EE Assets. All the training and validation matrices and accuracies can be saved as an Excel file in your working directory.<br/>\n",
    "**NOTE:** The input image needs to have the bands B1, B2, B3, B4, B5, B8, B11, B12 to apply masks correctly. The classifications will use only the bands B1, B2, B3, B4 and B2B3, which represent the bands that penetrates the most into the water column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Script by: Luis Lizcano-Sandoval<br/>\n",
    "College of Marine Sciences, University of South Florida<br/>\n",
    "Updated: 21/10/2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"4\">**Workflow:**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Import required images, collections, data, etc.\n",
    "2. Mask clouds, land, and deep areas >20m\n",
    "3. Apply Depth-Invariant Index (generates band-ratios B1B2, B1B3, B2B3)\n",
    "4. Sample bands: B1, B2, B3, B4, B2B3\n",
    "5. Train models and classify (CART, SVM and RF)\n",
    "6. Get confusion matrices and accuracies\n",
    "7. Export output to EE Assets (.tiff)\n",
    "8. Save matrices in local computer (.xlxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ee\n",
    "import pandas as pd\n",
    "import xlsxwriter\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.join(os.path.dirname(os.getcwd()),'bin'))\n",
    "from functions import CloudScore6S,landMaskFunction,div\n",
    "from IPython.display import display, Image\n",
    "\n",
    "ee.Initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "imageID = '20190117T161619_20190117T162429_T17RLM'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"4\">**1. Import files:**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import BOA Images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Satellite:  Sentinel-2B\n",
      "Tile:  17RLM\n",
      "Date:  2019-01-17\n"
     ]
    }
   ],
   "source": [
    "## Image Collection\n",
    "collection = ee.ImageCollection(\"users/lizcanosandoval/BOA/Sentinel/FL_19\")\n",
    "\n",
    "## Filter collection by image ID:\n",
    "imageTarget = collection.filter(ee.Filter.eq('file_id',imageID)).first()\n",
    "\n",
    "## more settings and metadata\n",
    "imageGeometry = imageTarget.geometry() #Tile geometry.\n",
    "imageSat = imageTarget.get('satellite').getInfo() #Image satellite\n",
    "imageTile = imageTarget.get('tile_id').getInfo() #Image tile id\n",
    "imageDate = imageTarget.get('date').getInfo() #Image date\n",
    "print('Satellite: ',imageSat)\n",
    "print('Tile: ',imageTile)\n",
    "print('Date: ',imageDate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://earthengine.googleapis.com/v1alpha/projects/earthengine-legacy/thumbnails/5f0e2cc110518a4864bd607ed580794e-5829b264d3c8fde55f551807d82457e5:getPixels\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rgb = ['B4','B3','B2']\n",
    "\n",
    "# Setting for displaying images:\n",
    "def displaySettings(image, channels):\n",
    "    img = Image(url=image.select(channels).getThumbUrl({\n",
    "        'dimensions': '500x500',\n",
    "        'min':0,\n",
    "        'max':0.2,\n",
    "        'gamma':1.5\n",
    "        }))\n",
    "    return display(img)\n",
    "\n",
    "## Display image:\n",
    "originalImage = displaySettings(imageTarget, rgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Ground-Points [Training and Validation] and sandy areas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sandy areas\n",
    "sand_areas = ee.FeatureCollection(\"users/lizcanosandoval/Sand\"),\n",
    "\n",
    "# Ground-Points\n",
    "springsCoast = ee.FeatureCollection(\"users/lizcanosandoval/ground-points/springs_coast-19\"),\n",
    "springsCoast_noDen = ee.FeatureCollection(\"users/lizcanosandoval/ground-points/springs_coast-19-noDensities\"),\n",
    "springsCoast_tra = ee.FeatureCollection(\"users/lizcanosandoval/ground-points/springs_coast-19_tra\"),\n",
    "springsCoast_val = ee.FeatureCollection(\"users/lizcanosandoval/ground-points/springs_coast-19_val\"),"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import other collections:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ETOPO1: Global 1 Arc-Minute Elevation:\n",
    "etopo = ee.Image(\"NOAA/NGDC/ETOPO1\")\n",
    "etopo = etopo.select('bedrock') ## Select the bathymetry band\n",
    "\n",
    "## Florida Bathymetry [NOAA-90m res]\n",
    "bathymetry = ee.Image(\"users/lizcanosandoval/Bathymetry_FL\")\n",
    "\n",
    "## Florida Land [from GADM-HiRes]\n",
    "gadm_FL = ee.FeatureCollection(\"users/lizcanosandoval/gadm36_FL\")\n",
    "\n",
    "## Florida's Seagrass Habitats (FWC database)\n",
    "seagrass = ee.FeatureCollection(\"users/lizcanosandoval/Seagrass_Habitat_Florida\"),\n",
    "\n",
    "## Sentinel-2 Tiles over seagrass areas:\n",
    "tiles = ee.FeatureCollection(\"users/lizcanosandoval/S2_tiles_surf-to-shallow_line\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"3\">**Visualization parameters:**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Palette:\n",
    "palette = ['030d81','0519ff','05e8ff','11ff01','fbff01','ff9901','ff0000','ad0000']\n",
    "## RGB\n",
    "rgbVis = {\\\n",
    "          'min': 0,\n",
    "          'max': 0.2,\n",
    "          'gamma': 2,\n",
    "          'bands': ['B4','B3','B2'],\n",
    "         }\n",
    "\n",
    "## Turbidity palette\n",
    "visTur = {\\\n",
    "         'bands': ['B5'],\n",
    "         'min': 0.01,\n",
    "         'max': 0.05,\n",
    "         'palette': palette,\n",
    "         }\n",
    "\n",
    "## Bathymetry palette\n",
    "visBath = {\\\n",
    "          'min': -20,\n",
    "          'max': 0,\n",
    "          'palette': palette,\n",
    "          }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"4\">**Prepare and mask bathymetry data:**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Mask depth ranges from the Etopo collection [from -25 to 1 meter]\n",
    "etopo_masked = ee.Image(etopo).updateMask(etopo.lt(1).And(etopo.gt(-25)))\n",
    "\n",
    "## Resample ETOPO\n",
    "etopo_resample = etopo_masked.reproject(**{\\\n",
    "                                         'crs': 'EPSG:32617',\n",
    "                                         'scale': 90,\n",
    "                                        })\n",
    "    \n",
    "## Define a boxcar or low-pass kernel.\n",
    "kernel = ee.Kernel.square(**{\\\n",
    "                           'radius': 3, \n",
    "                           'units': 'pixels', \n",
    "                           'normalize': True,\n",
    "                          })\n",
    "\n",
    "## Smooth raster\n",
    "#etopo_kernel = etopo_resample.resample('bilinear')\n",
    "etopo_kernel = etopo_resample.convolve(kernel)\n",
    "\n",
    "## Mask the FL bathymetry collection (NOAA):\n",
    "## Mask depth ranges from the FL bathymetry collection [Mask depth range from -20 to 2 meters]\n",
    "bathy_masked = ee.Image(bathymetry).updateMask(bathymetry.lt(2).And(bathymetry.gt(-25)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clip bathymetry to the tile geometry/bounds:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Clip bathymetry layers to tile geometry\n",
    "bathyBand = bathy_masked.clip(imageGeometry) ##Florida bathymetry clip (90m res)\n",
    "etopo_clip = etopo_kernel.clip(imageGeometry) ##Etopo clip + kernel (90m resampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the bathymetry dataset from NOAA has small gaps in some areas we need to fill them using the resampled ETOPO collection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Vectorize (to FeatureCollection of polygons) the bathymetry collection,\n",
    "## which is a raster image.\n",
    "bathyVector = bathyBand.toByte().reduceToVectors(**{\n",
    "  'reducer': ee.Reducer.countEvery(),\n",
    "  'crs': 'EPSG:4326',\n",
    "  'geometry': None,\n",
    "  'eightConnected': False,\n",
    "  'labelProperty': 'bathymetry',\n",
    "  'scale': 1000,\n",
    "  'geometryType': 'polygon',\n",
    "  'maxPixels': 1e9\n",
    "})\n",
    "\n",
    "## Extract the bathymetry values from the Etopo layer corresponding to the gap \n",
    "## found in the FL Bathymetry Data.\n",
    "bathyOutside = ee.Image.constant(1).clip(bathyVector).mask().Not()\n",
    "bathyGap = etopo_clip.updateMask(bathyOutside)\n",
    "bathyVectorGap = bathyGap.toByte().reduceToVectors(**{\n",
    "  'reducer': ee.Reducer.countEvery(),\n",
    "  'crs': 'EPSG:4326',\n",
    "  'geometry': None,\n",
    "  'eightConnected': False,\n",
    "  'labelProperty': 'bathymetry',\n",
    "  'scale': 1000,\n",
    "  'geometryType': 'polygon',\n",
    "  'maxPixels': 1e9\n",
    "});\n",
    "bathyVectorGap = bathyVectorGap.geometry().buffer(50) ##Fill gap and extend a buffer of 50m\n",
    "bathyOutside2 = ee.Image.constant(1).clip(bathyVectorGap).mask()\n",
    "bathyGap2 = etopo_clip.updateMask(bathyOutside2) ##Clip the gap in the ETOPO collection.\n",
    "\n",
    "#Finally, fill the gap in the NOAA bathymetry dataset. This is the new NOAA's bathymetry raster layer:\n",
    "bathyFilled = ee.ImageCollection([bathyBand,bathyGap2.select(['bedrock'],['b1'])]).mosaic()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"4\">**2. Apply masks to image:**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cloud mask:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Threshold value set to 2\n",
    "cloudMask = CloudScore6S(imageTarget, 2)\n",
    "\n",
    "## Display image:\n",
    "#cloudImage = displaySettings(cloudMask, rgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Land mask:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "landMask = landMaskFunction(cloudMask, gadm_FL)\n",
    "\n",
    "## Display image:\n",
    "#landImage = displaySettings(landMask, rgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bathymetry mask:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "bathyMask = landMask.clip(bathyVector) ##Using the NOAA dataset.\n",
    "\n",
    "## Display image:\n",
    "#bathyImage = displaySettings(bathyMask, rgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"4\">**3. Water column correction:**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sand polygons:  6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://earthengine.googleapis.com/v1alpha/projects/earthengine-legacy/thumbnails/dcd249455a828691837b7d94d168203e-191b62a0a6e893e60c146f20db02e93a:getPixels\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Filter sand polygons by tile/area:\n",
    "#sand = ee.FeatureCollection(sand_areas).filter(ee.Filter.eq('t_sentinel',tile))\n",
    "sand = ee.FeatureCollection(sand_areas).flatten().filterBounds(imageGeometry)\n",
    "print('Number of sand polygons: ',sand.size().getInfo())\n",
    "\n",
    "## Run the Depth-Invariant Index Function\n",
    "bands = ['B1','B2','B3'] #Select bands\n",
    "imageDIV = div(bathyMask, bands, sand)\n",
    "#print(imageDIV.getInfo())\n",
    "\n",
    "## Display one of the bands ['B1B2', 'B1B3', 'B2B3']\n",
    "# imgDIV = Image(url=imageDIV.select('B2B3').getThumbUrl({\n",
    "#     'dimensions': '500x500',\n",
    "#     'min':-3,\n",
    "#     'max':-1.5,\n",
    "#     'gamma':1.5\n",
    "#     }))\n",
    "# display(imgDIV)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"4\">**4. Sampling Data:**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classes are:\n",
    "* 0: Softbottom\n",
    "* 1: Hardbottom\n",
    "* 2: Seagrass\n",
    "* 3: Sparse seagrass //if available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes:  [0, 1, 2, 3]\n",
      "Ground Points per Class: {'0': 971, '1': 300, '2': 800, '3': 192}\n"
     ]
    }
   ],
   "source": [
    "## Collection with classes\n",
    "classNames = ee.FeatureCollection(springsCoast).flatten()\n",
    "print('Classes: ', classNames.aggregate_array('class').distinct().getInfo())\n",
    "\n",
    "## Add training and validation datasets separately.\n",
    "classTraining = ee.FeatureCollection(springsCoast_tra).flatten()\n",
    "classValidation = ee.FeatureCollection(springsCoast_val).flatten()\n",
    "numberClasses = classNames.aggregate_array('class').distinct().length()\n",
    "print('Ground Points per Class:', classNames.aggregate_histogram('class').getInfo())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select the bands to sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bands to sample: ['B1', 'B2', 'B3', 'B4', 'B2B3']\n"
     ]
    }
   ],
   "source": [
    "## Select bands to sample\n",
    "bandsClass = ['B1','B2', 'B3', 'B4','B2B3']\n",
    "\n",
    "## Add bands of interest to sample training points:\n",
    "imageClassify = bathyMask.addBands(imageDIV.select(['B2B3'])).select(bandsClass)\n",
    "print('Bands to sample:',imageClassify.bandNames().getInfo())\n",
    "##Other configurations:\n",
    "#imageClassify = imageDIV.select(bandsClass); // Depth invariant Bands B1B2,B1B3,B2B3.\n",
    "#imageClassify = imageKD.select(bandsClass)//.addBands(bathyFilled); //KD corr B1-B4, with or without bathymetry.\n",
    "\n",
    "## Define a boxcar or low-pass kernel (Used if want to smooth the image)\n",
    "smooth = ee.Kernel.euclidean(**{\n",
    "    'radius': 1, \n",
    "    'units': 'pixels', \n",
    "    'normalize': True\n",
    "})\n",
    "#imageClassify = imageClassify.convolve(smooth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample training and validation data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training size (70%): 1574\n"
     ]
    }
   ],
   "source": [
    "## Sample multi-spectral data using all ground points.\n",
    "trainingData = imageClassify.sampleRegions(**{\n",
    "    'collection': classTraining,\n",
    "    'properties': ['class'],\n",
    "    'scale': 10})\n",
    "print('Training size (70%):',trainingData.size().getInfo())\n",
    "\n",
    "validationData = imageClassify.sampleRegions(**{\n",
    "    'collection': classValidation,\n",
    "    'properties': ['class'],\n",
    "    'scale': 10})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"4\">**5. Train models and Classify:**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Train CART classifier\n",
    "trainCART = ee.Classifier.smileCart().train(trainingData,'class',bandsClass)\n",
    "\n",
    "## Train SVM classifier\n",
    "SVM = ee.Classifier.libsvm(**{\n",
    "   'kernelType': 'RBF',\n",
    "   'gamma': 100,\n",
    "   'cost': 100\n",
    "})\n",
    "trainSVM = SVM.train(**{\n",
    "   'features': trainingData,\n",
    "   'classProperty': 'class',\n",
    "   'inputProperties': bandsClass\n",
    "})\n",
    "\n",
    "## Train RF classifier\n",
    "trainRF = ee.Classifier.smileRandomForest(20).train(trainingData, 'class', bandsClass)\n",
    "\n",
    "#### Classify the image using the trained classifier\n",
    "classifiedCART = imageClassify.classify(trainCART)\n",
    "classifiedSVM = imageClassify.classify(trainSVM)\n",
    "classifiedRF = imageClassify.classify(trainRF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display classified images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://earthengine.googleapis.com/v1alpha/projects/earthengine-legacy/thumbnails/0f85e53ec8efca90660c4430986bb587-b27df8702f3cffb3bf840d42740bca1a:getPixels\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Define a palette for the distinct classes\n",
    "classPalette = ['#3090C7','#CD7F32','#004E00','#78F878']\n",
    "\n",
    "imgSVM = Image(url=classifiedSVM.getThumbUrl({\n",
    "    'dimensions': '500x500',\n",
    "    'min':0,\n",
    "    'max':3,\n",
    "    'palette': classPalette\n",
    "    }))\n",
    "display(imgSVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"4\">**6. Get accuracy matrices:**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training accuracies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cart Training overall accuracy:  0.9987\n",
      "SVM Training overall accuracy:  0.8577\n",
      "RF Training overall accuracy:  0.9759\n"
     ]
    }
   ],
   "source": [
    "## Get a confusion matrix representing resubstitution accuracy.\n",
    "## {Resubstitution error is the error of a model on the training data.}\n",
    "## Axis 0 (first level) of the matrix correspond to the input classes (columns), \n",
    "## and axis 1 (second level) to the output classes (rows).\n",
    "matrixTrainingCART = trainCART.confusionMatrix()\n",
    "matrixTrainingSVM = trainSVM.confusionMatrix()\n",
    "matrixTrainingRF = trainRF.confusionMatrix()\n",
    "\n",
    "#print('CART Training Confusion Matrix: ', matrixTrainingCART.getInfo())\n",
    "#print('SVM Training Confusion Matrix: ', matrixTrainingSVM.getInfo())\n",
    "#print('RF Training Confusion Matrix: ', matrixTrainingRF.getInfo())\n",
    "\n",
    "print('Cart Training overall accuracy: ', round((matrixTrainingCART.accuracy().getInfo()), 4))\n",
    "print('SVM Training overall accuracy: ', round((matrixTrainingSVM.accuracy().getInfo()), 4))\n",
    "print('RF Training overall accuracy: ', round((matrixTrainingRF.accuracy().getInfo()), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation accuracies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CART validation overall accuracy:  0.8292\n",
      "SVM validation overall accuracy:  0.8234\n",
      "RF Validation overall accuracy:  0.8613\n"
     ]
    }
   ],
   "source": [
    "## Calculate accuracy using validation data\n",
    "## Classify the image using the trained classifier\n",
    "validationCART = validationData.classify(trainCART)\n",
    "validationSVM = validationData.classify(trainSVM)\n",
    "validationRF = validationData.classify(trainRF)\n",
    "\n",
    "## Get a confusion matrix representing expected accuracy (Using validation points - 30%), where:\n",
    "#  0: Softbottom\n",
    "#  1: Hardbottom\n",
    "#  2: Dense Seagrass\n",
    "#  3: Spare Seagrass\n",
    "\n",
    "## Axis 0 (the rows) of the matrix correspond to the actual values, \n",
    "## and Axis 1 (the columns) to the predicted values.\n",
    "errorMx = {'actual': 'class', 'predicted': 'classification'}\n",
    "errorMatrixCART = validationCART.errorMatrix(**errorMx)\n",
    "errorMatrixSVM = validationSVM.errorMatrix(**errorMx)\n",
    "errorMatrixRF = validationRF.errorMatrix(**errorMx)\n",
    "\n",
    "#print('CART Validation Error Matrix: ', errorMatrixCART.getInfo())\n",
    "#print('SVM Validation Error Matrix: ', errorMatrixSVM.getInfo())\n",
    "#print('RF Validation Error Matrix: ', errorMatrixRF.getInfo())\n",
    "\n",
    "print('CART validation overall accuracy: ', round((errorMatrixCART.accuracy().getInfo()), 4))\n",
    "print('SVM validation overall accuracy: ', round((errorMatrixSVM.accuracy().getInfo()), 4))\n",
    "print('RF Validation overall accuracy: ', round((errorMatrixRF.accuracy().getInfo()), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "User and Producer accuracies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Producer Accuracy SVM:  [[0.86], [0.7261904761904762], [0.8724279835390947], [0.5689655172413793]]\n",
      "User Accuracy SVM:  [[0.821656050955414, 0.6931818181818182, 0.8760330578512396, 0.8048780487804879]]\n"
     ]
    }
   ],
   "source": [
    "## Estimate user and producer accuracies\n",
    "producerAccuracyCART = errorMatrixCART.producersAccuracy()\n",
    "producerAccuracySVM = errorMatrixSVM.producersAccuracy()\n",
    "producerAccuracyRF = errorMatrixRF.producersAccuracy()\n",
    "\n",
    "userAccuracyCART = errorMatrixCART.consumersAccuracy()\n",
    "userAccuracySVM = errorMatrixSVM.consumersAccuracy()\n",
    "userAccuracyRF = errorMatrixRF.consumersAccuracy()\n",
    "\n",
    "#print('Producer Accuracy CART: ',producerAccuracyCART.getInfo())\n",
    "#print('Producer Accuracy SVM: ',producerAccuracySVM.getInfo())\n",
    "#print('Producer Accuracy RF: ',producerAccuracyRF.getInfo())\n",
    "#print('User Accuracy CART: ',userAccuracyCART.getInfo())\n",
    "#print('User Accuracy SVM: ',userAccuracySVM.getInfo())\n",
    "#print('User Accuracy RF: ',userAccuracyRF.getInfo())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print accuracies as Pandas format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " CART: \n",
      "     Producer      User\n",
      "Sb  0.830000  0.849829\n",
      "Hb  0.821429  0.711340\n",
      "Dn  0.876543  0.880165\n",
      "Sp  0.637931  0.698113\n",
      "\n",
      " SVM: \n",
      "     Producer      User\n",
      "Sb  0.860000  0.821656\n",
      "Hb  0.726190  0.693182\n",
      "Dn  0.872428  0.876033\n",
      "Sp  0.568966  0.804878\n",
      "\n",
      " RF: \n",
      "     Producer      User\n",
      "Sb  0.900000  0.859873\n",
      "Hb  0.773810  0.792683\n",
      "Dn  0.909465  0.894737\n",
      "Sp  0.586207  0.809524\n"
     ]
    }
   ],
   "source": [
    "## Create a pandas dataframe with producer and user accuracies:\n",
    "rowIndex = {0:'Sb', 1:'Hb', 2:'Dn', 3:'Sp'}\n",
    "dfPA_CART = pd.DataFrame(producerAccuracyCART.getInfo(), columns=['Producer'])\n",
    "dfUA_CART = pd.DataFrame(userAccuracyCART.getInfo()).transpose()\n",
    "dfPA_SVM = pd.DataFrame(producerAccuracySVM.getInfo(), columns=['Producer'])\n",
    "dfUA_SVM = pd.DataFrame(userAccuracySVM.getInfo()).transpose()\n",
    "dfPA_RF = pd.DataFrame(producerAccuracyRF.getInfo(), columns=['Producer'])\n",
    "dfUA_RF = pd.DataFrame(userAccuracyRF.getInfo()).transpose()\n",
    "\n",
    "PU_CART = pd.concat([dfPA_CART, dfUA_CART.rename(columns={0:'User'})], axis=1).rename(index=rowIndex)\n",
    "PU_SVM = pd.concat([dfPA_SVM, dfUA_SVM.rename(columns={0:'User'})], axis=1).rename(index=rowIndex)\n",
    "PU_RF = pd.concat([dfPA_RF, dfUA_RF.rename(columns={0:'User'})], axis=1).rename(index=rowIndex)\n",
    "\n",
    "print(' CART: \\n', PU_CART)\n",
    "print('\\n SVM: \\n', PU_SVM)\n",
    "print('\\n RF: \\n', PU_RF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kappa coefficients:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kappa CART:  0.7425\n",
      "Kappa SVM:  0.7295\n",
      "Kappa RF:  0.7871\n"
     ]
    }
   ],
   "source": [
    "# The Kappa Coefficient is generated from a statistical test to evaluate the accuracy \n",
    "# of a classification. Kappa essentially evaluate how well the classification performed \n",
    "# as compared to just randomly assigning values, i.e. did the classification do better \n",
    "# than random. The Kappa Coefficient can range from -1 t0 1. A value of 0 indicated that \n",
    "# the classification is no better than a random classification. A negative number \n",
    "# indicates the classification is significantly worse than random. A value close to 1 \n",
    "# indicates that the classification is significantly better than random.\n",
    "\n",
    "kappaCART = errorMatrixCART.kappa()\n",
    "kappaSVM = errorMatrixSVM.kappa()\n",
    "kappaRF = errorMatrixRF.kappa()\n",
    "\n",
    "print('Kappa CART: ', round((kappaCART.getInfo()), 4))\n",
    "print('Kappa SVM: ', round((kappaSVM.getInfo()), 4))\n",
    "print('Kappa RF: ', round((kappaRF.getInfo()), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"4\">**7. Export Classified Images:**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wait for submission\n",
      "Classified Image 1: 20190117T161619_20190117T162429_T17RLM_CART submitted...\n",
      "Classified Image 2: 20190117T161619_20190117T162429_T17RLM_SVM submitted...\n",
      "Classified Image 3: 20190117T161619_20190117T162429_T17RLM_RF submitted...\n",
      "All images submitted!\n"
     ]
    }
   ],
   "source": [
    "# Set the scale properly\n",
    "scale = []\n",
    "sat = []\n",
    "method = ['CART','SVM','RF']\n",
    "classifiedCollection = ee.ImageCollection([classifiedCART,classifiedSVM,classifiedRF])\n",
    "classifiedList = classifiedCollection.toList(classifiedCollection.size())\n",
    "classifiedSize = classifiedList.size().getInfo()\n",
    "print('Wait for submission')\n",
    "\n",
    "for i in range(classifiedSize):\n",
    "    if 'Sentinel' in imageSat:\n",
    "        sat = 'Sentinel'\n",
    "        scale = 10 #For Sentinel\n",
    "    else:\n",
    "        sat = 'Landsat'\n",
    "        scale = 30 #For Landsat \n",
    "        \n",
    "    ## Select image\n",
    "    image = ee.Image(classifiedList.get(i))\n",
    "    \n",
    "    # set some properties for export\n",
    "    output = image.set({'satellite': imageSat,\n",
    "                   'tile_id': imageTile,\n",
    "                   'file_id': imageID,                                               \n",
    "                   'date': imageDate,\n",
    "                   'classifier': method[i],\n",
    "                   'generator': 'Lizcano-Sandoval',\n",
    "                        })\n",
    "\n",
    "    # define YOUR assetID. (This do not create folders, you need to create them manually)\n",
    "    assetID = 'users/lizcanosandoval/Seagrass/'+sat+'/'+'FL_19/' ##This goes to an ImageCollection folder\n",
    "    fileName = imageTile+'_'+imageID+'_'+ method[i]\n",
    "    path = assetID + fileName\n",
    "    \n",
    "    ## Batch Export to Assets\n",
    "    ee.batch.Export.image.toAsset(\\\n",
    "        image = ee.Image(output),                                                    \n",
    "        description = method[i]+'_'+imageID,\n",
    "        assetId = path,\n",
    "        region = imageGeometry.buffer(10),                                      \n",
    "        maxPixels = 1e13,\n",
    "        scale = scale).start()\n",
    "    print('Classified Image '+str(i+1)+': '+imageID+'_'+ method[i]+' submitted...')\n",
    "print('All images submitted!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"4\">**8. Save Matrices to Working Directory:**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract values from each matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This matrices needs to be reformatted:  [[667, 0, 0, 0], [1, 215, 0, 0], [1, 0, 556, 0], [0, 0, 0, 134]]\n"
     ]
    }
   ],
   "source": [
    "CART_trainingMatrix = matrixTrainingCART.array().getInfo()\n",
    "CART_trainingAccuracy = matrixTrainingCART.accuracy().getInfo()\n",
    "CART_errorMatrix = errorMatrixCART.array().getInfo()\n",
    "CART_errorAccuracy = errorMatrixCART.accuracy().getInfo()\n",
    "CART_producerAccuracy = producerAccuracyCART.getInfo()\n",
    "CART_userAccuracy = userAccuracyCART.getInfo()\n",
    "CART_kappa = kappaCART.getInfo()\n",
    "SVM_trainingMatrix = matrixTrainingSVM.array().getInfo()\n",
    "SVM_trainingAccuracy = matrixTrainingSVM.accuracy().getInfo()\n",
    "SVM_errorMatrix = errorMatrixSVM.array().getInfo()\n",
    "SVM_errorAccuracy = errorMatrixSVM.accuracy().getInfo()\n",
    "SVM_producerAccuracy = producerAccuracySVM.getInfo()\n",
    "SVM_userAccuracy = userAccuracySVM.getInfo()\n",
    "SVM_kappa = kappaSVM.getInfo()\n",
    "RF_trainingMatrix = matrixTrainingRF.array().getInfo()\n",
    "RF_trainingAccuracy = matrixTrainingRF.accuracy().getInfo()\n",
    "RF_errorMatrix = errorMatrixRF.array().getInfo()\n",
    "RF_errorAccuracy = errorMatrixRF.accuracy().getInfo()\n",
    "RF_producerAccuracy = producerAccuracyRF.getInfo()\n",
    "RF_userAccuracy = userAccuracyRF.getInfo()\n",
    "RF_kappa = kappaRF.getInfo()\n",
    "\n",
    "print('These matrices needs to be reformatted, e.g.: ', CART_trainingMatrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert matrices to pandas dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style><table id=\"T_0062c2ed_13b9_11eb_bf6f_54bf641ff7ff\" ><caption>Kappa coefficients</caption><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >Kappa</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_0062c2ed_13b9_11eb_bf6f_54bf641ff7fflevel0_row0\" class=\"row_heading level0 row0\" >CART</th>\n",
       "                        <td id=\"T_0062c2ed_13b9_11eb_bf6f_54bf641ff7ffrow0_col0\" class=\"data row0 col0\" >0.742545</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_0062c2ed_13b9_11eb_bf6f_54bf641ff7fflevel0_row1\" class=\"row_heading level0 row1\" >SVM</th>\n",
       "                        <td id=\"T_0062c2ed_13b9_11eb_bf6f_54bf641ff7ffrow1_col0\" class=\"data row1 col0\" >0.729531</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_0062c2ed_13b9_11eb_bf6f_54bf641ff7fflevel0_row2\" class=\"row_heading level0 row2\" >RF</th>\n",
       "                        <td id=\"T_0062c2ed_13b9_11eb_bf6f_54bf641ff7ffrow2_col0\" class=\"data row2 col0\" >0.787114</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x26c10a4b910>"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Training Matrices\n",
    "TM_CART = pd.DataFrame(CART_trainingMatrix).rename(columns=rowIndex, index=rowIndex)\n",
    "TM_SVM = pd.DataFrame(SVM_trainingMatrix).rename(columns=rowIndex, index=rowIndex)\n",
    "TM_RF = pd.DataFrame(RF_trainingMatrix).rename(columns=rowIndex, index=rowIndex)\n",
    "TM_concat = pd.concat([TM_CART, TM_SVM, TM_RF], keys=['CART','SVM','RF'])\n",
    "\n",
    "#Training Accuracies\n",
    "TA_CART = pd.Series(CART_trainingAccuracy)\n",
    "TA_SVM = pd.Series(SVM_trainingAccuracy)\n",
    "TA_RF = pd.Series(RF_trainingAccuracy)\n",
    "TA_concat = pd.DataFrame(pd.concat([TA_CART, TA_SVM, TA_RF],ignore_index=True), columns=(['Tr_Accuracy']))\\\n",
    "                .rename({0:'CART',1:'SVM',2:'RF'})\n",
    "\n",
    "#Validation-Error Matrices\n",
    "VM_CART = pd.DataFrame(CART_errorMatrix).rename(columns=rowIndex, index=rowIndex)\n",
    "VM_SVM = pd.DataFrame(SVM_errorMatrix).rename(columns=rowIndex, index=rowIndex)\n",
    "VM_RF = pd.DataFrame(RF_errorMatrix).rename(columns=rowIndex, index=rowIndex)\n",
    "VM_concat = pd.concat([VM_CART, VM_SVM, VM_RF], keys=['CART','SVM','RF'])\n",
    "\n",
    "#Validation Accuracies\n",
    "VA_CART = pd.Series(CART_errorAccuracy)\n",
    "VA_SVM = pd.Series(SVM_errorAccuracy)\n",
    "VA_RF = pd.Series(RF_errorAccuracy)\n",
    "VA_concat = pd.DataFrame(pd.concat([VA_CART, VA_SVM, VA_RF],ignore_index=True), columns=(['Va_Accuracy']))\\\n",
    "                .rename({0:'CART',1:'SVM',2:'RF'})\n",
    "\n",
    "#Producer-User Accuracies\n",
    "PU_concat = pd.concat([PU_CART, PU_SVM, PU_RF], keys=['CART','SVM','RF'])\n",
    "\n",
    "#Kappa coefficients\n",
    "Kp_CART = pd.Series(CART_kappa)\n",
    "Kp_SVM = pd.Series(SVM_kappa)\n",
    "Kp_RF = pd.Series(RF_kappa)\n",
    "Kp_concat = pd.DataFrame(pd.concat([Kp_CART, Kp_SVM, Kp_RF],ignore_index=True), columns=(['Kappa']))\\\n",
    "                .rename({0:'CART',1:'SVM',2:'RF'})\n",
    "\n",
    "Kp_concat.style.set_caption('Kappa coefficients')\n",
    "#print(Kp_concat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Organize each matrix in separate excel sheets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "excelName = 'Mrx_'+imageID+'.xlsx'\n",
    "excel = pd.ExcelWriter(excelName, engine='xlsxwriter')\n",
    "\n",
    "TM_concat.to_excel(excel, sheet_name='TrMrx', index=True, startrow=0)\n",
    "TA_concat.to_excel(excel, sheet_name='TrAcc', index=True, startrow=0)\n",
    "VM_concat.to_excel(excel, sheet_name='VaMrx', index=True, startrow=0)\n",
    "VA_concat.to_excel(excel, sheet_name='VaAcc', index=True, startrow=0)\n",
    "PU_concat.to_excel(excel, sheet_name='PU-Mrx', index=True, startrow=0)\n",
    "Kp_concat.to_excel(excel, sheet_name='Kappa', index=True, startrow=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save matrices as .xlsx file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "excel.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
