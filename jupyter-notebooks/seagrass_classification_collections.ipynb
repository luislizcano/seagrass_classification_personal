{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automated Seagrass Classification Using Earth Engine Python API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script classify seagrass beds in selected BOA images using ground-data to train three machine learning classifiers: CART, Support Vector Machine and Random Forest. The outputs can be exported to EE Assets. All the training and validation matrices and accuracies can be saved as an Excel file in your working directory.<br/>\n",
    "**NOTE:** The input image needs to have the bands B1, B2, B3, B4, B5, B8, B11, B12 to apply masks correctly. The classifications will use only the bands B1, B2, B3, B4 and Blue/Green, which represent the bands that penetrates the most into the water column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Script by: Luis Lizcano-Sandoval<br/>\n",
    "College of Marine Sciences, University of South Florida<br/>\n",
    "Updated: 11/16/2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"4\">**Workflow:**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Import required images, collections, data, etc.\n",
    "2. Mask clouds, land, and deep areas >20m\n",
    "3. Apply Depth-Invariant Index (generates band-ratios B1B2, B1B3, B2B3)\n",
    "4. Sample bands: B1, B2, B3, B4, B/G\n",
    "5. Train models and classify (CART, SVM and RF)\n",
    "6. Get confusion matrices and accuracies\n",
    "7. Export output to EE Assets (.tiff)\n",
    "8. Save matrices in local computer (.xlxs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load required libraries:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ee\n",
    "import pandas as pd\n",
    "import xlsxwriter\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.join(os.path.dirname(os.getcwd()),'bin'))\n",
    "import datetime\n",
    "from functions import CloudScore6S,landMaskFunction,DII\n",
    "\n",
    "ee.Initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1.257\n"
     ]
    }
   ],
   "source": [
    "print(ee.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Insert the ID of the image of interest and folder from the personal Assets:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Select set of images belonging to a same satellite sensor and year.\n",
    "\n",
    "## Sentinel 2\n",
    "imageList = [\n",
    "'20210314T155929_20210314T160346_T17RLL',\n",
    "'20210413T155819_20210413T161213_T17RLL',\n",
    "'20210309T160101_20210309T161423_T17RLM',\n",
    "'20210106T161649_20210106T162243_T17RLM',\n",
    "'20210309T160101_20210309T161423_T17RLM'\n",
    "]\n",
    "\n",
    "## Landsat list\n",
    "# 2019\n",
    "# imageList = [\n",
    "# 'LE07_017040_20190223',\n",
    "# 'LE07_017040_20191005']\n",
    "\n",
    "# 2000\n",
    "# imageList = [\n",
    "# 'LE07_017040_20000914',\n",
    "# 'LT05_017040_20000602']\n",
    "\n",
    "# 1990\n",
    "# imageList = [\n",
    "# 'LT05_017041_20101121',\n",
    "# 'LT05_017041_20101004',\n",
    "# 'LT05_017041_20101020',\n",
    "# 'LT05_017041_20090118',\n",
    "# 'LT05_017041_20110313'\n",
    "# ]\n",
    "\n",
    "# for i in range(len(imageList)):\n",
    "#     print(imageList[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Some metadata:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collections loaded\n"
     ]
    }
   ],
   "source": [
    "#boaFolder = 'FL_10'\n",
    "exportFolder = 'FL_21'\n",
    "dataFolder = 'Ground-points-19'\n",
    "#dataFolder = 'Ground-points-00'\n",
    "#dataFolder = 'TB_10' ##Ground-truth data\n",
    "smoothStr = '_raw_' #Smooth or not? '_smooth_' or '_raw_'\n",
    "\n",
    "## Image Collection - For use only if BOA Folder is active.\n",
    "#collection = ee.ImageCollection(\"users/lizcanosandoval/BOA/Sentinel/\"+boaFolder)\n",
    "#collection = ee.ImageCollection(\"users/lizcanosandoval/BOA/Landsat/\"+boaFolder)\n",
    "\n",
    "###########################    IMPORT TRAINING DATA    #########################\n",
    "\n",
    "# Sandy areas\n",
    "sand_areas = ee.FeatureCollection(\"users/lizcanosandoval/ground-points/Sand\")\n",
    "\n",
    "# Ground-Points\n",
    "groundPoints = ee.FeatureCollection(\"users/lizcanosandoval/ground-points/\"+dataFolder)\n",
    "#groundPoints = ee.FeatureCollection(\"users/lizcanosandoval/ground-points/Turkey_2020\")\n",
    "\n",
    "\n",
    "## IMPORT OTHER COLLECTIONS:\n",
    "\n",
    "## ETOPO1: Global 1 Arc-Minute Elevation:\n",
    "#etopo = ee.Image(\"NOAA/NGDC/ETOPO1\")\n",
    "#etopo = etopo.select('bedrock') ## Select the bathymetry band\n",
    "\n",
    "## Florida Bathymetry [NOAA-90m res]\n",
    "#bathymetry = ee.Image(\"users/lizcanosandoval/Bathymetry_FL\")\n",
    "\n",
    "## Florida Land [from GADM-HiRes]\n",
    "#gadm_FL = ee.FeatureCollection(\"users/lizcanosandoval/gadm36_FL\")\n",
    "gadm_FL = ee.FeatureCollection(\"users/lizcanosandoval/Florida_10m\") ##Created from NDWI using Sentinel-2 imagery\n",
    "#gadm_FL = ee.FeatureCollection(\"users/lizcanosandoval/Turkey_gadm\")\n",
    "#gadm_FL = ee.ImageCollection(\"users/lizcanosandoval/WaterMask_Turkey\")\n",
    "\n",
    "\n",
    "## FAO Global Administrative Unit Layers 2015, Country Boundaries\n",
    "#FAO = ee.FeatureCollection(\"FAO/GAUL/2015/level0\")\n",
    "\n",
    "## Filter country. To select country by GAUL code see: http://www.fao.org/countryprofiles/iso3list/en/\n",
    "#country = FAO.filter(ee.Filter.eq('ADM0_CODE',256))\n",
    "\n",
    "## Florida's Seagrass Habitats (FWC database)\n",
    "#seagrass = ee.FeatureCollection(\"users/lizcanosandoval/Seagrass_Habitat_Florida\"),\n",
    "\n",
    "## Sentinel-2 Tiles over seagrass areas:\n",
    "#tiles = ee.FeatureCollection(\"users/lizcanosandoval/S2_tiles_surf-to-shallow_line\")\n",
    "print('Collections loaded')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Start classification loop:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initiating...\n",
      "Preparing image 20201124T160609_20201124T161304_T17RLM\n",
      "Image masked...\n",
      "Depth-Invariant index applied...\n",
      "Training models and classifying...\n",
      "Getting accuracies...\n",
      "Exporting classified images to EE Assets...\n",
      "Classified Image 1: 20201124T160609_20201124T161304_T17RLM_raw_CART submitted...\n",
      "Classified Image 2: 20201124T160609_20201124T161304_T17RLM_raw_SVM submitted...\n",
      "Classified Image 3: 20201124T160609_20201124T161304_T17RLM_raw_RF submitted...\n",
      "Classified images submitted!\n",
      "Saving matrices to working directory...\n",
      "Saved Matrices of 20201124T160609_20201124T161304_T17RLM\n",
      "Initiating...\n",
      "Preparing image 20200203T160451_20200203T161119_T17RLM\n",
      "Image masked...\n",
      "Depth-Invariant index applied...\n",
      "Training models and classifying...\n",
      "Getting accuracies...\n",
      "Exporting classified images to EE Assets...\n",
      "Classified Image 1: 20200203T160451_20200203T161119_T17RLM_raw_CART submitted...\n",
      "Classified Image 2: 20200203T160451_20200203T161119_T17RLM_raw_SVM submitted...\n",
      "Classified Image 3: 20200203T160451_20200203T161119_T17RLM_raw_RF submitted...\n",
      "Classified images submitted!\n",
      "Saving matrices to working directory...\n",
      "Saved Matrices of 20200203T160451_20200203T161119_T17RLM\n",
      "Initiating...\n",
      "Preparing image 20201025T160249_20201025T161241_T17RLM\n",
      "Image masked...\n",
      "Depth-Invariant index applied...\n",
      "Training models and classifying...\n",
      "Getting accuracies...\n",
      "Exporting classified images to EE Assets...\n",
      "Classified Image 1: 20201025T160249_20201025T161241_T17RLM_raw_CART submitted...\n",
      "Classified Image 2: 20201025T160249_20201025T161241_T17RLM_raw_SVM submitted...\n",
      "Classified Image 3: 20201025T160249_20201025T161241_T17RLM_raw_RF submitted...\n",
      "Classified images submitted!\n",
      "Saving matrices to working directory...\n",
      "Saved Matrices of 20201025T160249_20201025T161241_T17RLM\n",
      "ALL IMAGES HAVE BEEN CLASSIFIED!\n",
      "Wall time: 6min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## Initiate loop:\n",
    "for i in range(len(imageList)):\n",
    "    print('Initiating...')\n",
    "    imageID = imageList[i]\n",
    "    \n",
    "    print('Preparing image '+imageID)\n",
    "    \n",
    "\n",
    "\n",
    "    ## Filter collection by image ID:\n",
    "#     imageTarget = collection.filter(ee.Filter.eq('file_id',imageID)).first() ## for use if BOA folder is used\n",
    "    ##Settings if SR collection is used instead of BOA Folder:\n",
    "    imageTarget = ee.Image('COPERNICUS/S2_SR/'+imageID)\n",
    "    imageTarget = imageTarget.divide(10000).set(imageTarget.toDictionary(imageTarget.propertyNames()))\n",
    "    imageSat = imageTarget.get('SPACECRAFT_NAME').getInfo()\n",
    "    imageTile = imageTarget.get('MGRS_TILE').getInfo()\n",
    "    ee_date = imageTarget.get('GENERATION_TIME').getInfo()\n",
    "    imageDate = str(datetime.datetime.utcfromtimestamp(ee_date/1000.0))\n",
    "    \n",
    "    ## more settings and metadata (if images are in BOA folder-GEE Assets)\n",
    "    imageGeometry = imageTarget.geometry() #Tile geometry. For use always.\n",
    "#     imageSat = imageTarget.get('satellite').getInfo() #Image satellite\n",
    "#     imageTile = imageTarget.get('tile_id').getInfo() #Image tile id\n",
    "#     imageDate = imageTarget.get('date').getInfo() #Image date\n",
    "\n",
    "    if 'Sentinel' in imageSat:\n",
    "        imageScale = 10 # Sentinel resolution\n",
    "    else:\n",
    "        imageScale = 30 # Landsat resolution\n",
    "\n",
    "    \n",
    "    \n",
    "    ###########################    PREPARE BATHYMETRY DATA    #########################\n",
    "\n",
    "#     ## Mask depth ranges from the Etopo collection [from -25 to 1 meter]\n",
    "#     etopo_masked = ee.Image(etopo).updateMask(etopo.lt(1).And(etopo.gt(-25)))\n",
    "\n",
    "#     ## Resample ETOPO\n",
    "#     etopo_resample = etopo_masked.reproject(**{\\\n",
    "#                                              'crs': 'EPSG:32617',\n",
    "#                                              'scale': 90,\n",
    "#                                             })\n",
    "\n",
    "#     ## Define a boxcar or low-pass kernel.\n",
    "#     kernel = ee.Kernel.square(**{\\\n",
    "#                                'radius': 3, \n",
    "#                                'units': 'pixels', \n",
    "#                                'normalize': True,\n",
    "#                               })\n",
    "\n",
    "#     ## Smooth raster\n",
    "#     #etopo_kernel = etopo_resample.resample('bilinear')\n",
    "#     etopo_kernel = etopo_resample.convolve(kernel)\n",
    "\n",
    "#     ## Mask the FL bathymetry collection (NOAA):\n",
    "#     ## Mask depth ranges from the FL bathymetry collection [Mask depth range from -20 to 2 meters]\n",
    "#     bathy_masked = ee.Image(bathymetry).updateMask(bathymetry.lt(2).And(bathymetry.gt(-25)))\n",
    "\n",
    "#     ## Clip bathymetry layers to tile geometry\n",
    "#     bathyBand = bathy_masked.clip(imageGeometry) ##Florida bathymetry clip (90m res)\n",
    "#     etopo_clip = etopo_kernel.clip(imageGeometry) ##Etopo clip + kernel (90m resampled)\n",
    "\n",
    "#     ## Vectorize (to FeatureCollection of polygons) the bathymetry collection,\n",
    "#     ## which is a raster image.\n",
    "#     bathyVector = bathyBand.toByte().reduceToVectors(**{\n",
    "#       'reducer': ee.Reducer.countEvery(),\n",
    "#       'crs': 'EPSG:4326',\n",
    "#       'geometry': None,\n",
    "#       'eightConnected': False,\n",
    "#       'labelProperty': 'bathymetry',\n",
    "#       'scale': 1000,\n",
    "#       'geometryType': 'polygon',\n",
    "#       'maxPixels': 1e9\n",
    "#     })\n",
    "\n",
    "#     ## Extract the bathymetry values from the Etopo layer corresponding to the gap \n",
    "#     ## found in the FL Bathymetry Data.\n",
    "#     bathyOutside = ee.Image.constant(1).clip(bathyVector).mask().Not()\n",
    "#     bathyGap = etopo_clip.updateMask(bathyOutside)\n",
    "#     bathyVectorGap = bathyGap.toByte().reduceToVectors(**{\n",
    "#       'reducer': ee.Reducer.countEvery(),\n",
    "#       'crs': 'EPSG:4326',\n",
    "#       'geometry': None,\n",
    "#       'eightConnected': False,\n",
    "#       'labelProperty': 'bathymetry',\n",
    "#       'scale': 1000,\n",
    "#       'geometryType': 'polygon',\n",
    "#       'maxPixels': 1e9\n",
    "#     });\n",
    "#     bathyVectorGap = bathyVectorGap.geometry().buffer(50) ##Fill gap and extend a buffer of 50m\n",
    "#     bathyOutside2 = ee.Image.constant(1).clip(bathyVectorGap).mask()\n",
    "#     bathyGap2 = etopo_clip.updateMask(bathyOutside2) ##Clip the gap in the ETOPO collection.\n",
    "\n",
    "#     #Finally, fill the gap in the NOAA bathymetry dataset. This is the new NOAA's bathymetry raster layer:\n",
    "#     bathyFilled = ee.ImageCollection([bathyBand,bathyGap2.select(['bedrock'],['b1'])]).mosaic()\n",
    "\n",
    "\n",
    "    ###########################    CLOUD MASK    #########################\n",
    "\n",
    "    ## Recommended Threshold values for\n",
    "    ## *Sentinel: 2\n",
    "    ## *Landsat: 5\n",
    "    if 'Sentinel' in imageSat:\n",
    "        threshold = 5\n",
    "    else:\n",
    "        threshold = 5\n",
    "\n",
    "    ## Apply cloud mask\n",
    "    cloudMask = CloudScore6S(imageSat, imageTarget, threshold)\n",
    "\n",
    "\n",
    "    ###########################    LAND MASK    #########################\n",
    "\n",
    "    ## Apply land mask\n",
    "    landMask = landMaskFunction(cloudMask, gadm_FL)\n",
    "    #landMask = cloudMask.updateMask(gadm_FL.mosaic())\n",
    "\n",
    "\n",
    "    ###########################    BATHYMETRY MASK    #########################\n",
    "\n",
    "    ## Apply bathymetry mask\n",
    "    bathyMask = landMask#.clip(bathyVector) ##Using the NOAA dataset: bathyVector\n",
    "\n",
    "\n",
    "    ###########################    TURBIDITY MASK    #########################\n",
    "\n",
    "    ## Turbidity masking is based on the red band reflectances. Based on own observations, values higher than 0.02-0.03 \n",
    "    ## indicates turbid waters, but sometimes may indicate shallow seagrass banks. So the below algorithm try to separate \n",
    "    ## shallow seagrass from turbidity.\n",
    "\n",
    "    ## Set parameter values\n",
    "    if 'Sentinel' in imageSat:\n",
    "        red_band = 'B4' #Red seems work better in this case than B5.\n",
    "        red_thr_inf = 0.025\n",
    "        red_thr_sup = 0.2\n",
    "        green_band = 'B3'\n",
    "        green_thr = 0.15\n",
    "        blue_band = 'B2'\n",
    "        blue_thr = 0.11\n",
    "    elif 'Landsat8' in imageSat:\n",
    "        red_band = 'B4'\n",
    "        red_thr_inf = 0.025\n",
    "        red_thr_sup = 0.2\n",
    "        green_band = 'B3'\n",
    "        green_thr = 0.15\n",
    "        blue_band = 'B2'\n",
    "        blue_thr = 0.11\n",
    "    else:\n",
    "        red_band = 'B3'\n",
    "        red_thr_inf = 0.03 #Landsat5/7 are less sensitive\n",
    "        red_thr_sup = 0.2\n",
    "        green_band = 'B2'\n",
    "        green_thr = 0.15\n",
    "        blue_band = 'B1'\n",
    "        blue_thr = 0.11\n",
    "\n",
    "    ## Select the red band\n",
    "    selectRedBand = bathyMask.select('B4')\n",
    "\n",
    "    ## Identify turbid areas first (pixel values higher than the threshold)\n",
    "    turbidMask = selectRedBand.gt(red_thr_inf)\n",
    "\n",
    "    ## Apply thresholds on red, green and blue bands\n",
    "    maskRed = selectRedBand.gt(red_thr_inf).And(selectRedBand.lt(red_thr_sup))\n",
    "    imageMaskRed = bathyMask.mask(maskRed)\n",
    "    maskGreen = imageMaskRed.select(green_band).lt(green_thr)\n",
    "    imageMaskGreen = imageMaskRed.mask(maskGreen)\n",
    "    maskBlue = imageMaskGreen.select(blue_band).lt(blue_thr) ##Shallow seagrass\n",
    "\n",
    "    ## Final mask (excluding seagrass/including turbid water)\n",
    "    turbidImage = bathyMask.mask(turbidMask) ## Turbidity\n",
    "    seagrassImage = bathyMask.mask(maskBlue).mask().Not() ## Shallow seagrass (inverse mask)\n",
    "    excludeSeagrass = turbidImage.updateMask(seagrassImage) ## Turbidity minus shallow seagrass\n",
    "    finalMaskImage = bathyMask.mask(excludeSeagrass)\n",
    "    finalMask = finalMaskImage.mask().Not()\n",
    "\n",
    "    ## Final Image\n",
    "    finalImage = bathyMask.updateMask(finalMask)\n",
    "    print('Image masked...')\n",
    "\n",
    "    ###########################    WATER COLUMN CORRECTION    #########################    \n",
    "\n",
    "    ## Filter sand polygons by tile/area:\n",
    "    #sand = ee.FeatureCollection(sand_areas).flatten().filterBounds(imageGeometry)\n",
    "    sand = ee.FeatureCollection(sand_areas).filterBounds(imageGeometry)\n",
    "\n",
    "    ## Run the Depth-Invariant Index Function\n",
    "    imageDII = DII(finalImage, imageScale, sand)\n",
    "\n",
    "    print('Depth-Invariant index applied...')\n",
    "\n",
    "    ###########################    SAMPLING    #########################\n",
    "    # Classes are:\n",
    "\n",
    "    # 0: Softbottom\n",
    "    # 1: Hardbottom\n",
    "    # 2: Seagrass\n",
    "    # 3: Sparse seagrass //if available\n",
    "\n",
    "    ## Filter ground points by tile geometry and display classes\n",
    "    filterPoints = ee.FeatureCollection(groundPoints).filterBounds(imageGeometry)\n",
    "\n",
    "    ## Select bands to sample. The B/G band is B2B3 in Sentinel-2 and Landsat-8, and B1B2 for Landsat-7/5\n",
    "    if 'Sentinel' in imageSat or 'Landsat8' in imageSat:\n",
    "        bandsClass = ['B1','B2', 'B3', 'B4','B2B3']\n",
    "        bg = ['B2B3']\n",
    "    else:\n",
    "        bandsClass = ['B1','B2', 'B3', 'B1B2']\n",
    "        bg = ['B1B2']\n",
    "\n",
    "    ## Add bands of interest to sample training points:\n",
    "    imageClassify = finalImage.addBands(imageDII.select(bg)).select(bandsClass)\n",
    "    ##Other configurations:\n",
    "    #imageClassify = imageDII.select(bandsClass); // Depth invariant Bands B1B2,B1B3,B2B3.\n",
    "    #imageClassify = imageKD.select(bandsClass)//.addBands(bathyFilled); //KD corr B1-B4, with or without bathymetry.\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    ###########################    MAKE TRAINING WITHIN THE 5KM BOUNDS OF SEAGRASS HABITATS    #########################\n",
    "    ## Focuses on the known seagrass areas including a buffer area of 5 km.\n",
    "    seagrass_buffer = ee.FeatureCollection(\"users/lizcanosandoval/Seagrass_Habitat_Florida_buff5k\")\n",
    "#     shallowMask = ee.ImageCollection(\"users/lizcanosandoval/Shallow_Mask_FL\")\n",
    "#     specificTurbidMask = ee.ImageCollection(\"users/lizcanosandoval/TurbidityMask\")\n",
    "#     listShallowMask = shallowMask.aggregate_array('system:index').getInfo()\n",
    "#     listTurbidMask = specificTurbidMask.aggregate_array('system:index').getInfo()\n",
    "\n",
    "    imageClassify = imageClassify.clip(seagrass_buffer)\n",
    "    \n",
    "#     ##If image has a specific shallow water mask then apply it:\n",
    "#     if imageTile in listShallowMask:\n",
    "#         imageClassify = imageClassify.updateMask(shallowMask.mosaic())\n",
    "\n",
    "#     ##If image has a specific turbidity mask then apply it:\n",
    "#     if imageID in listTurbidMask:\n",
    "#         filterTurbidMask = ee.Image(specificTurbidMask.filter(ee.Filter.eq('system:index',imageID)).first())\n",
    "#         mask = filterTurbidMask.Not()\n",
    "#         imageClassify = imageClassify.updateMask(mask)\n",
    "\n",
    "#     #buffer = ee.FeatureCollection(\"users/lizcanosandoval/Turkey_coastline_buffer_1km\")\n",
    "#     #imageClassify = imageClassify.clip(buffer)\n",
    "#     clipper = ee.FeatureCollection(\"users/lizcanosandoval/ground-points/AOI_SpringsCoast\")\n",
    "#     imageClassify = imageClassify.clip(clipper)\n",
    "    \n",
    "\n",
    "    ###########################    APPLY SMOOTHER    #########################\n",
    "    ## Define a boxcar or low-pass kernel (Used if want to smooth the image)\n",
    "    smooth = ee.Kernel.euclidean(**{\n",
    "        'radius': 1, \n",
    "        'units': 'pixels', \n",
    "        'normalize': True\n",
    "    })\n",
    "    \n",
    "    ## Apply smoother if set:\n",
    "    if 'smooth' in smoothStr:\n",
    "        imageClassify = imageClassify.convolve(smooth)\n",
    "    \n",
    "\n",
    "    ###########################    GET TRAINING AND VALIDATION DATA    #########################\n",
    "\n",
    "    ## Sample multi-spectral data using all ground points.\n",
    "    samplingData = imageClassify.sampleRegions(**{\n",
    "        'collection': filterPoints,\n",
    "        'properties': ['class'],\n",
    "        'scale': imageScale})\n",
    "\n",
    "    ## Add random numbers to each feature (from 0 to 1).\n",
    "    randomData = samplingData.randomColumn(\"random\",0)\n",
    "\n",
    "    ## Split ground data in training (~70%) and validation (~30%) points\n",
    "    trainingData = randomData.filter(ee.Filter.lt(\"random\",0.7))\n",
    "    validationData = randomData.filter(ee.Filter.gte(\"random\", 0.7))\n",
    "\n",
    "\n",
    "\n",
    "    ###########################    TRAIN MODELS AND CLASSIFY    #########################\n",
    "    print('Training models and classifying...')\n",
    "    ## Train CART classifier\n",
    "    trainCART = ee.Classifier.smileCart().train(trainingData,'class',bandsClass)\n",
    "\n",
    "    ## Train SVM classifier\n",
    "    SVM = ee.Classifier.libsvm(**{\n",
    "       'kernelType': 'RBF',\n",
    "       'gamma': 100,\n",
    "       'cost': 100\n",
    "    })\n",
    "    trainSVM = SVM.train(**{\n",
    "       'features': trainingData,\n",
    "       'classProperty': 'class',\n",
    "       'inputProperties': bandsClass\n",
    "    })\n",
    "\n",
    "    ## Train RF classifier\n",
    "    trainRF = ee.Classifier.smileRandomForest(20).train(trainingData, 'class', bandsClass)\n",
    "\n",
    "    #### Classify the image using the trained classifier\n",
    "    classifiedCART = imageClassify.classify(trainCART)\n",
    "    classifiedSVM = imageClassify.classify(trainSVM)\n",
    "    classifiedRF = imageClassify.classify(trainRF)\n",
    "    \n",
    "    ######### Load seagrass mask 2019 and clip, to clean #########\n",
    "    seagrass_mask = ee.ImageCollection(\"users/lizcanosandoval/Seagrass/SeagrassMask_FL_50m\").mosaic()\n",
    "    classifiedCART = classifiedCART.updateMask(seagrass_mask)\n",
    "    classifiedSVM = classifiedSVM.updateMask(seagrass_mask) #For raster\n",
    "    classifiedRF = classifiedRF.updateMask(seagrass_mask)\n",
    "\n",
    "\n",
    "    ###########################    TRAINING ACCURACIES    #########################\n",
    "    print('Getting accuracies...')\n",
    "    ## Get a confusion matrix representing resubstitution accuracy.\n",
    "    ## {Resubstitution error is the error of a model on the training data.}\n",
    "    ## Axis 0 (first level) of the matrix correspond to the input classes (columns), \n",
    "    ## and axis 1 (second level) to the output classes (rows).\n",
    "    matrixTrainingCART = trainCART.confusionMatrix()\n",
    "    matrixTrainingSVM = trainSVM.confusionMatrix()\n",
    "    matrixTrainingRF = trainRF.confusionMatrix()\n",
    "\n",
    "\n",
    "    ###########################    VALIDATION ACCURACIES    #########################\n",
    "\n",
    "    ## Calculate accuracy using validation data\n",
    "    ## Classify the image using the trained classifier\n",
    "    validationCART = validationData.classify(trainCART)\n",
    "    validationSVM = validationData.classify(trainSVM)\n",
    "    validationRF = validationData.classify(trainRF)\n",
    "\n",
    "    ## Get a confusion matrix representing expected accuracy (Using validation points - 30%), where:\n",
    "    #  0: Softbottom\n",
    "    #  1: Hardbottom\n",
    "    #  2: Dense Seagrass\n",
    "    #  3: Spare Seagrass\n",
    "\n",
    "    ## Axis 0 (the rows) of the matrix correspond to the actual values, \n",
    "    ## and Axis 1 (the columns) to the predicted values.\n",
    "    errorMx = {'actual': 'class', 'predicted': 'classification'}\n",
    "    errorMatrixCART = validationCART.errorMatrix(**errorMx)\n",
    "    errorMatrixSVM = validationSVM.errorMatrix(**errorMx)\n",
    "    errorMatrixRF = validationRF.errorMatrix(**errorMx)\n",
    "\n",
    "\n",
    "    ###########################    USER/PRODUCER ACCURACIES    #########################\n",
    "\n",
    "    ## Estimate user and producer accuracies\n",
    "    producerAccuracyCART = errorMatrixCART.producersAccuracy()\n",
    "    producerAccuracySVM = errorMatrixSVM.producersAccuracy()\n",
    "    producerAccuracyRF = errorMatrixRF.producersAccuracy()\n",
    "\n",
    "    # USER\n",
    "    userAccuracyCART = errorMatrixCART.consumersAccuracy()\n",
    "    userAccuracySVM = errorMatrixSVM.consumersAccuracy()\n",
    "    userAccuracyRF = errorMatrixRF.consumersAccuracy()\n",
    "\n",
    "\n",
    "    ###########################    KAPPA COEFFICIENTS    #########################\n",
    "\n",
    "    # The Kappa Coefficient is generated from a statistical test to evaluate the accuracy \n",
    "    # of a classification. Kappa essentially evaluate how well the classification performed \n",
    "    # as compared to just randomly assigning values, i.e. did the classification do better \n",
    "    # than random. The Kappa Coefficient can range from -1 to 1. A value of 0 indicated that \n",
    "    # the classification is no better than a random classification. A negative number \n",
    "    # indicates the classification is significantly worse than random. A value close to 1 \n",
    "    # indicates that the classification is significantly better than random.\n",
    "    kappaCART = errorMatrixCART.kappa()\n",
    "    kappaSVM = errorMatrixSVM.kappa()\n",
    "    kappaRF = errorMatrixRF.kappa()\n",
    "\n",
    "\n",
    "\n",
    "    ###########################    EXPORT CLASSIFIED IMAGES    #########################\n",
    "\n",
    "    # Set the scale properly\n",
    "    scale = []\n",
    "    sat = []\n",
    "    method = ['CART','SVM','RF']\n",
    "    classifiedCollection = ee.ImageCollection([classifiedCART,classifiedSVM,classifiedRF])\n",
    "    classifiedList = classifiedCollection.toList(classifiedCollection.size())\n",
    "    classifiedSize = classifiedList.size().getInfo()\n",
    "    print('Exporting classified images to EE Assets...')\n",
    "\n",
    "    for i in range(classifiedSize):\n",
    "\n",
    "        # Rename satellite\n",
    "        if 'Sentinel' in imageSat:\n",
    "            sat = 'Sentinel'\n",
    "        else:\n",
    "            sat = 'Landsat'\n",
    "\n",
    "        ## Select image\n",
    "        image = ee.Image(classifiedList.get(i))\n",
    "\n",
    "        # set some properties for export\n",
    "        output = image.set({'satellite': imageSat,\n",
    "                       'tile_id': imageTile,\n",
    "                       'file_id': imageID,                                               \n",
    "                       'date': imageDate,\n",
    "                       'year': imageDate[0:4],\n",
    "                       'classifier': method[i],\n",
    "                       'generator': 'Lizcano-Sandoval',\n",
    "                            })\n",
    "\n",
    "        # define YOUR assetID. (This do not create folders, you need to create them manually)\n",
    "        assetID = 'users/lizcanosandoval/Seagrass/'+sat+'/'+exportFolder+'/' ##This goes to an ImageCollection folder\n",
    "        fileName = imageID+smoothStr+ method[i]\n",
    "        path = assetID + fileName\n",
    "\n",
    "        ## Batch Export to Assets\n",
    "        ee.batch.Export.image.toAsset(\\\n",
    "            image = ee.Image(output),                                                    \n",
    "            description = method[i] +smoothStr+ imageID,\n",
    "            assetId = path,\n",
    "            region = imageGeometry.buffer(10),                                      \n",
    "            maxPixels = 1e13,\n",
    "            scale = imageScale).start()\n",
    "        print('Classified Image '+str(i+1)+': '+imageID +smoothStr+ method[i]+' submitted...')\n",
    "    print('Classified images submitted!')\n",
    "\n",
    "\n",
    "\n",
    "    ###########################    SAVE MATRICES TO WORKING DIRECTORY    #########################\n",
    "    print('Saving matrices to working directory...')\n",
    "    # Extract values from each matrix\n",
    "    CART_trainingMatrix = matrixTrainingCART.array().getInfo()\n",
    "    CART_trainingAccuracy = matrixTrainingCART.accuracy().getInfo()\n",
    "    CART_errorMatrix = errorMatrixCART.array().getInfo()\n",
    "    CART_errorAccuracy = errorMatrixCART.accuracy().getInfo()\n",
    "    CART_producerAccuracy = producerAccuracyCART.getInfo()\n",
    "    CART_userAccuracy = userAccuracyCART.getInfo()\n",
    "    CART_kappa = kappaCART.getInfo()\n",
    "    SVM_trainingMatrix = matrixTrainingSVM.array().getInfo()\n",
    "    SVM_trainingAccuracy = matrixTrainingSVM.accuracy().getInfo()\n",
    "    SVM_errorMatrix = errorMatrixSVM.array().getInfo()\n",
    "    SVM_errorAccuracy = errorMatrixSVM.accuracy().getInfo()\n",
    "    SVM_producerAccuracy = producerAccuracySVM.getInfo()\n",
    "    SVM_userAccuracy = userAccuracySVM.getInfo()\n",
    "    SVM_kappa = kappaSVM.getInfo()\n",
    "    RF_trainingMatrix = matrixTrainingRF.array().getInfo()\n",
    "    RF_trainingAccuracy = matrixTrainingRF.accuracy().getInfo()\n",
    "    RF_errorMatrix = errorMatrixRF.array().getInfo()\n",
    "    RF_errorAccuracy = errorMatrixRF.accuracy().getInfo()\n",
    "    RF_producerAccuracy = producerAccuracyRF.getInfo()\n",
    "    RF_userAccuracy = userAccuracyRF.getInfo()\n",
    "    RF_kappa = kappaRF.getInfo()\n",
    "\n",
    "    ## Convert matrices to pandas dataframes:\n",
    "    #Training Matrices\n",
    "    rowIndex = {0:'Sb', 1:'Hb', 2:'Dn', 3:'Sp'}\n",
    "    TM_CART = pd.DataFrame(CART_trainingMatrix).rename(columns=rowIndex, index=rowIndex)\n",
    "    TM_SVM = pd.DataFrame(SVM_trainingMatrix).rename(columns=rowIndex, index=rowIndex)\n",
    "    TM_RF = pd.DataFrame(RF_trainingMatrix).rename(columns=rowIndex, index=rowIndex)\n",
    "    TM_concat = pd.concat([TM_CART, TM_SVM, TM_RF], keys=['CART','SVM','RF'])\n",
    "\n",
    "    #Training Accuracies\n",
    "    TA_CART = pd.Series(CART_trainingAccuracy)\n",
    "    TA_SVM = pd.Series(SVM_trainingAccuracy)\n",
    "    TA_RF = pd.Series(RF_trainingAccuracy)\n",
    "    TA_concat = pd.DataFrame(pd.concat([TA_CART, TA_SVM, TA_RF],ignore_index=True), columns=(['Tr_Accuracy']))\\\n",
    "                    .rename({0:'CART',1:'SVM',2:'RF'})\n",
    "\n",
    "    #Validation-Error Matrices\n",
    "    VM_CART = pd.DataFrame(CART_errorMatrix).rename(columns=rowIndex, index=rowIndex)\n",
    "    VM_SVM = pd.DataFrame(SVM_errorMatrix).rename(columns=rowIndex, index=rowIndex)\n",
    "    VM_RF = pd.DataFrame(RF_errorMatrix).rename(columns=rowIndex, index=rowIndex)\n",
    "    VM_concat = pd.concat([VM_CART, VM_SVM, VM_RF], keys=['CART','SVM','RF'])\n",
    "\n",
    "    #Validation Accuracies\n",
    "    VA_CART = pd.Series(CART_errorAccuracy)\n",
    "    VA_SVM = pd.Series(SVM_errorAccuracy)\n",
    "    VA_RF = pd.Series(RF_errorAccuracy)\n",
    "    VA_concat = pd.DataFrame(pd.concat([VA_CART, VA_SVM, VA_RF],ignore_index=True), columns=(['Va_Accuracy']))\\\n",
    "                    .rename({0:'CART',1:'SVM',2:'RF'})\n",
    "\n",
    "    #Producer-User Accuracies\n",
    "    ## Create a pandas dataframe with producer and user accuracies:\n",
    "    dfPA_CART = pd.DataFrame(producerAccuracyCART.getInfo(), columns=['Producer'])\n",
    "    dfUA_CART = pd.DataFrame(userAccuracyCART.getInfo()).transpose()\n",
    "    dfPA_SVM = pd.DataFrame(producerAccuracySVM.getInfo(), columns=['Producer'])\n",
    "    dfUA_SVM = pd.DataFrame(userAccuracySVM.getInfo()).transpose()\n",
    "    dfPA_RF = pd.DataFrame(producerAccuracyRF.getInfo(), columns=['Producer'])\n",
    "    dfUA_RF = pd.DataFrame(userAccuracyRF.getInfo()).transpose()\n",
    "\n",
    "    PU_CART = pd.concat([dfPA_CART, dfUA_CART.rename(columns={0:'User'})], axis=1).rename(index=rowIndex)\n",
    "    PU_SVM = pd.concat([dfPA_SVM, dfUA_SVM.rename(columns={0:'User'})], axis=1).rename(index=rowIndex)\n",
    "    PU_RF = pd.concat([dfPA_RF, dfUA_RF.rename(columns={0:'User'})], axis=1).rename(index=rowIndex)\n",
    "    PU_concat = pd.concat([PU_CART, PU_SVM, PU_RF], keys=['CART','SVM','RF'])\n",
    "\n",
    "    # Kappa coefficients\n",
    "    Kp_CART = pd.Series(CART_kappa)\n",
    "    Kp_SVM = pd.Series(SVM_kappa)\n",
    "    Kp_RF = pd.Series(RF_kappa)\n",
    "    Kp_concat = pd.DataFrame(pd.concat([Kp_CART, Kp_SVM, Kp_RF],ignore_index=True), columns=(['Kappa']))\\\n",
    "                    .rename({0:'CART',1:'SVM',2:'RF'})\n",
    "\n",
    "    # Extract the number of training and validation points per class:\n",
    "    trainingInfo = trainingData.aggregate_histogram('class').getInfo()\n",
    "    validationInfo = validationData.aggregate_histogram('class').getInfo()\n",
    "\n",
    "    traSeries = pd.Series(trainingInfo)\n",
    "    valSeries = pd.Series(validationInfo)\n",
    "\n",
    "    Points_concat = pd.DataFrame(pd.concat([traSeries, valSeries],ignore_index=True,axis=1))\\\n",
    "                    .rename(columns={0:'TraPoints',1:'ValPoints'}).rename({'0':'Sb','1':'Hb','2':'Dn'},axis='index')\n",
    "    \n",
    "    # Organize each matrix in separate excel sheets\n",
    "    excelName = 'Mrx'+ smoothStr + imageID +'.xlsx'\n",
    "    excel = pd.ExcelWriter(excelName, engine='xlsxwriter')\n",
    "\n",
    "    Points_concat.to_excel(excel, sheet_name='Points', index=True, startrow=0)\n",
    "    TM_concat.to_excel(excel, sheet_name='TrMrx', index=True, startrow=0)\n",
    "    TA_concat.to_excel(excel, sheet_name='TrAcc', index=True, startrow=0)\n",
    "    VM_concat.to_excel(excel, sheet_name='VaMrx', index=True, startrow=0)\n",
    "    VA_concat.to_excel(excel, sheet_name='VaAcc', index=True, startrow=0)\n",
    "    PU_concat.to_excel(excel, sheet_name='PU-Mrx', index=True, startrow=0)\n",
    "    Kp_concat.to_excel(excel, sheet_name='Kappa', index=True, startrow=0)\n",
    "\n",
    "    # Save matrices as .xlsx file:\n",
    "    excel.save()\n",
    "    print('Saved Matrices of '+imageID)\n",
    "\n",
    "print('ALL IMAGES HAVE BEEN CLASSIFIED!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
