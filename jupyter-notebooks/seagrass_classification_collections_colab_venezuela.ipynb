{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.2"
    },
    "colab": {
      "name": "seagrass_classification_collections_colab.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kkc23H-J7mvm"
      },
      "source": [
        "# Semi-Automated Seagrass Classification Using Earth Engine Python API"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TZEfGRkG7mvp"
      },
      "source": [
        "This script classify seagrass beds in selected BOA images using ground-data to train the Support Vector Machine classifier. The outputs can be exported to EE Assets. All the training and validation matrices and accuracies can be saved as an Excel file in your working directory.<br/>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "StRlEBwi7mvq"
      },
      "source": [
        "Script by: Luis Lizcano-Sandoval<br/>\n",
        "College of Marine Sciences, University of South Florida<br/>\n",
        "luislizcanos@usf.edu\n",
        "Updated: 11/11/2021"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YtoTq1yw7mvr"
      },
      "source": [
        "<font size=\"4\">**Workflow:**</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UvH1rPqO7mvr"
      },
      "source": [
        "1. Import required images, collections, data, etc.\n",
        "2. Mask clouds and land\n",
        "3. Apply Depth-Invariant Index (generates band-ratios B1B2, B1B3, B2B3)\n",
        "4. Sample bands: B1, B2, B3, B4, B/G\n",
        "5. Train models and classify (CART, SVM and RF)\n",
        "6. Get confusion matrices and accuracies\n",
        "7. Export output to EE Assets (.tiff)\n",
        "8. Save matrices in local computer (.xlxs)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iSypAzax7vs3",
        "outputId": "9b91130d-c37a-4719-bd52-58d0aadcc956",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "## Run this cell to mount your Google Drive\n",
        "import os, sys\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "nb_path = '/content/notebooks'\n",
        "os.symlink('/content/drive/My Drive/Colab Notebooks', nb_path)\n",
        "sys.path.insert(0, nb_path)  # or append(nb_path)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KxZOkVNh7vzc",
        "outputId": "0b9dd87f-3df0-42c4-a00d-cb0ce56c1608",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "## Authenticate your EE account\n",
        "!earthengine authenticate"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "To authorize access needed by Earth Engine, open the following URL in a web browser and follow the instructions. If the web browser does not start automatically, please manually browse the URL below.\n",
            "\n",
            "    https://accounts.google.com/o/oauth2/auth?client_id=517222506229-vsmmajv00ul0bs7p89v5m89qs8eb9359.apps.googleusercontent.com&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fearthengine+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdevstorage.full_control&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&response_type=code&code_challenge=JbEmKG7ilCMmNsCrol_IzUUo6AfeXobYHGNqrokk-HY&code_challenge_method=S256\n",
            "\n",
            "The authorization workflow will generate a code, which you should paste in the box below. \n",
            "Enter verification code: 4/1AX4XfWjJY8iNUsv-ApG8nik0Z1yLG5dQAQGmLtMEBEAF23gg0qxl2smCXBk\n",
            "\n",
            "Successfully saved authorization token.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HOieAPGS7v3e",
        "outputId": "2b80dd5d-422a-470e-dcaf-7a4b5a15e872",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "## Install some libraries:\n",
        "!pip install xlsxwriter"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting xlsxwriter\n",
            "  Downloading XlsxWriter-3.0.2-py3-none-any.whl (149 kB)\n",
            "\u001b[?25l\r\u001b[K     |██▏                             | 10 kB 24.1 MB/s eta 0:00:01\r\u001b[K     |████▍                           | 20 kB 28.0 MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 30 kB 20.9 MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 40 kB 17.1 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 51 kB 9.3 MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 61 kB 9.4 MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 71 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 81 kB 8.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 92 kB 9.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 102 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 112 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 122 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 133 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 143 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 149 kB 8.6 MB/s \n",
            "\u001b[?25hInstalling collected packages: xlsxwriter\n",
            "Successfully installed xlsxwriter-3.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3alEOlxc70Ga",
        "outputId": "b21a38fc-38da-4fbd-f736-8d1509b024d5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "## Clone github repo:\n",
        "!git clone https://github.com/luislizcano/ee_seagrass_classification.git"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ee_seagrass_classification'...\n",
            "remote: Enumerating objects: 88, done.\u001b[K\n",
            "remote: Counting objects: 100% (88/88), done.\u001b[K\n",
            "remote: Compressing objects: 100% (84/84), done.\u001b[K\n",
            "remote: Total 88 (delta 41), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (88/88), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oXQkPAN37mvr"
      },
      "source": [
        "**Load required libraries:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Svqhr6A87mvs"
      },
      "source": [
        "import os, sys\n",
        "sys.path.insert(0,'/content/ee_seagrass_classification')\n",
        "sys.path.append('/content/ee_seagrass_classification/bin/')\n",
        "import ee\n",
        "import pandas as pd\n",
        "import xlsxwriter\n",
        "import os\n",
        "import sys\n",
        "sys.path.append(os.path.join(os.path.dirname(os.getcwd()),'bin'))\n",
        "import datetime\n",
        "# from functions import CloudScore6S,landMaskFunction,DII\n",
        "\n",
        "ee.Initialize()"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OEfRgGdg7mvt",
        "outputId": "416cccc7-b858-4e17-ccdf-cd6ea1949cd1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "## Verify you loaded the EE module correctly:\n",
        "from functions import CloudScore6S,landMaskFunction,DII\n",
        "print('EE version: ',ee.__version__)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EE version:  0.1.290\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bUZ-UcKK7mvu"
      },
      "source": [
        "**Insert the ID of the image of interest and folder from the personal Assets:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WB6mRF9s7mvv"
      },
      "source": [
        "## Select set of images belonging to a same satellite sensor and year.\n",
        "## cienaga: 19PFM; PtoAzul: 19PGM; PNM: 19PEN\n",
        "## Sentinel 2\n",
        "imageList = [\n",
        "'20200522T150731_20200522T150726_T19PEN',\n",
        "'20200527T150719_20200527T150721_T19PEN'\n",
        "]\n",
        "\n",
        "## Landsat list\n",
        "# 2019\n",
        "# imageList = [\n",
        "# 'LE07_017040_20190223',\n",
        "# 'LE07_017040_20191005']\n",
        "\n",
        "# 2000\n",
        "# imageList = [\n",
        "# 'LE07_017040_20000914',\n",
        "# 'LT05_017040_20000602']\n",
        "\n",
        "# 1990\n",
        "# imageList = [\n",
        "# 'LT05_017041_19990904',\n",
        "# 'LT05_017041_19991107',\n",
        "# 'LT05_017041_19990107'\n",
        "# ]\n",
        "\n",
        "# for i in range(len(imageList)):\n",
        "#     print(imageList[i])"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DHQKbp-C7mvv"
      },
      "source": [
        "**Some metadata:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gcUX9hBr7mvv"
      },
      "source": [
        "## Define the source of your image, if from your EE Assets or EE Collections:\n",
        "# imageSource = 'assets'  ## BOA imagery from EE Assets\n",
        "imageSource = 'ee'      ## BOA imagery from EE Collections\n",
        "\n",
        "## Define the type of satellite imagery\n",
        "satellite = 'Sentinel2'\n",
        "# satellite = 'Landsat8'\n",
        "# satellite = 'Landsat7'\n",
        "# satellite = 'Landsat5'\n",
        "\n",
        "## Some settings:\n",
        "regionName = 'cienaga' ## Region to classify [from ´regions´ collection below]\n",
        "#boaFolder = 'FL_20' ## Name of folder with BOA images in assets.\n",
        "exportFolder = 'Cienaga_20' ## Name of EE folder to save the final output\n",
        "dataFolder = 'Ground-points-19' ## EE Folder with Ground-truth points\n",
        "smoothStr = '_raw_' # Smooth classified pixels or not? options: '_smooth_' or '_raw_'"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uiKEreDYN3FZ"
      },
      "source": [
        "**Import data:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYJyy1YfN0z6",
        "outputId": "1a6cf554-f25c-4429-ab0c-8952d2968edc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "###########################    IMPORT TRAINING DATA    #########################\n",
        "\n",
        "# Sandy areas\n",
        "sand_areas = ee.FeatureCollection(\"users/anacaroperalta/datos/sand_poly_2020\")\n",
        "\n",
        "# Ground-Points\n",
        "groundPoints = ee.FeatureCollection(\"users/anacaroperalta/datos/puntos_clasificacion2020\")\n",
        "#groundPoints = ee.FeatureCollection(\"users/lizcanosandoval/ground-points/Turkey_2020\")\n",
        "\n",
        "## Landmask\n",
        "#land = ee.FeatureCollection(\"users/lizcanosandoval/Florida_10m\") ##Created from NDWI using Sentinel-2 imagery\n",
        "mask1 = ee.Image('users/anacaroperalta/datos/waterMask_PNM_S')\n",
        "mask2 = ee.Image('users/anacaroperalta/datos/waterMask_PtoAzul_19PGM')\n",
        "mask3 = ee.Image('users/anacaroperalta/datos/waterMask_cienaga_202019PFM')\n",
        "\n",
        "land = ee.ImageCollection([mask1,mask2,mask3]) ##Created from NDWI using Sentinel-2 imagery\n",
        "\n",
        "## Region polygons: (cienaga,PtoAzul, PNM)\n",
        "regions = ee.FeatureCollection(\"users/anacaroperalta/datos/poligonosinteres\")\n",
        "\n",
        "print('Collections loaded')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collections loaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YgI9hnsW7mvw"
      },
      "source": [
        "**Start classification loop:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0zdkQSWd7mvx",
        "outputId": "08e8ec70-6116-4a35-ccd9-2a06b6974c18",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 623
        }
      },
      "source": [
        "%%time\n",
        "print('Initiating...')\n",
        "\n",
        "## Initiate loop:\n",
        "for i in range(len(imageList)):\n",
        "    imageID = imageList[i]\n",
        "    \n",
        "    print('Preparing image '+imageID)\n",
        "    \n",
        "    #############################   Prepare image metadata  ##################################\n",
        "\n",
        "    ## If the image source is your asset, then define the folder where the satellite image is:\n",
        "    if 'assets'== imageSource:\n",
        "        ## Load BOA image from assets:\n",
        "        if 'Sentinel' in satellite:\n",
        "            imageTarget = ee.Image(\"users/lizcanosandoval/BOA/Sentinel/\"+boaFolder+'/'+imageID)\n",
        "        elif 'Landsat' in satellite:\n",
        "            imageTarget = ee.Image(\"users/lizcanosandoval/BOA/Landsat/\"+boaFolder+'/'+imageID)\n",
        "\n",
        "    ## If the image source is an EE collection, then define the satellite collection:\n",
        "    if 'ee'== imageSource:\n",
        "        ## Load BOA image collection from assets:\n",
        "        if 'Sentinel' in satellite:\n",
        "            image = ee.Image(\"COPERNICUS/S2_SR/\"+imageID)\n",
        "        elif 'Landsat8' == satellite:\n",
        "            image = ee.Image(\"LANDSAT/LC08/C01/T1_SR/\"+imageID)\n",
        "        elif 'Landsat7' == satellite:\n",
        "            image = ee.Image(\"LANDSAT/LE07/C01/T1_SR/\"+imageID)\n",
        "        elif 'Landsat5' == satellite:\n",
        "            image = ee.Image(\"LANDSAT/LT05/C01/T1_SR/\"+imageID)\n",
        "\n",
        "    ## Get image metadata:\n",
        "    if 'assets'== imageSource:\n",
        "        imageSat = imageTarget.get('satellite').getInfo() #Image satellite\n",
        "        imageTile = imageTarget.get('tile_id').getInfo() #Image tile id\n",
        "        imageDate = imageTarget.get('date').getInfo() #Image date\n",
        "        imageGeometry = imageTarget.geometry() #Tile geometry.\n",
        "\n",
        "    if 'ee'== imageSource:\n",
        "        if 'Sentinel' in satellite:\n",
        "            imageTarget = image.divide(10000).set(image.toDictionary(image.propertyNames()))\n",
        "            imageSat = imageTarget.get('SPACECRAFT_NAME').getInfo() #Image satellite\n",
        "            imageTile = imageTarget.get('MGRS_TILE').getInfo() #Image tile id\n",
        "            ee_date = imageTarget.get('GENERATION_TIME').getInfo()\n",
        "            imageDate = str(datetime.datetime.utcfromtimestamp(ee_date/1000.0)) #Image date\n",
        "            imageGeometry = imageTarget.geometry() #Tile geometry.\n",
        "        elif 'Landsat8' == satellite:\n",
        "            imageTarget = image.divide(10000).set(image.toDictionary(image.propertyNames()))\n",
        "            #imageSat = imageTarget.get('SATELLITE').getInfo() #Image satellite\n",
        "            imageSat = satellite\n",
        "            imageTile = str(imageTarget.get('WRS_PATH').getInfo())+str(imageTarget.get('WRS_ROW').getInfo()) #Image tile id\n",
        "            imageDate = imageTarget.get('SENSING_TIME').getInfo()\n",
        "            imageGeometry = imageTarget.geometry() #Tile geometry.\n",
        "\n",
        "    if 'Sentinel' in imageSat:\n",
        "        imageScale = 10 # Sentinel resolution\n",
        "    else:\n",
        "        imageScale = 30 # Landsat resolution\n",
        "\n",
        "    \n",
        "    ###########################    CLOUD MASK    #########################\n",
        "\n",
        "    ## Recommended Threshold values for\n",
        "    ## *Sentinel: 2\n",
        "    ## *Landsat: 5\n",
        "    if 'Sentinel' in imageSat:\n",
        "        threshold = 5\n",
        "    else:\n",
        "        threshold = 5\n",
        "\n",
        "    ## Apply cloud mask\n",
        "    cloudMask = CloudScore6S(imageSat, imageTarget, threshold)\n",
        "\n",
        "\n",
        "    ###########################    LAND MASK    #########################\n",
        "\n",
        "    ## Apply land mask\n",
        "    #landMask = landMaskFunction(cloudMask, land) ## Use if Land is a featureCollection\n",
        "    landMask = cloudMask.mask(land.mosaic()) ## Use if Land is an imageCollection\n",
        "\n",
        "\n",
        "    ###########################    BATHYMETRY MASK    #########################\n",
        "\n",
        "    ## Apply bathymetry mask\n",
        "    bathyMask = landMask#.clip(bathyVector) ##Using the NOAA dataset: bathyVector\n",
        "\n",
        "\n",
        "    ###########################    TURBIDITY MASK    #########################\n",
        "\n",
        "    ## Turbidity masking is based on the red band reflectances. Based on own observations, values higher than 0.02-0.03 \n",
        "    ## indicates turbid waters, but sometimes may indicate shallow seagrass banks. So the below algorithm try to separate \n",
        "    ## shallow seagrass from turbidity.\n",
        "\n",
        "    ## Set parameter values\n",
        "    if 'Sentinel' in imageSat:\n",
        "        red_band = 'B4' #Red seems work better in this case than B5.\n",
        "        red_thr_inf = 0.025\n",
        "        red_thr_sup = 0.2\n",
        "        green_band = 'B3'\n",
        "        green_thr = 0.15\n",
        "        blue_band = 'B2'\n",
        "        blue_thr = 0.11\n",
        "    elif 'Landsat8' in imageSat:\n",
        "        red_band = 'B4'\n",
        "        red_thr_inf = 0.025\n",
        "        red_thr_sup = 0.2\n",
        "        green_band = 'B3'\n",
        "        green_thr = 0.15\n",
        "        blue_band = 'B2'\n",
        "        blue_thr = 0.11\n",
        "    else:\n",
        "        red_band = 'B3'\n",
        "        red_thr_inf = 0.03 #Landsat5/7 are less sensitive\n",
        "        red_thr_sup = 0.2\n",
        "        green_band = 'B2'\n",
        "        green_thr = 0.15\n",
        "        blue_band = 'B1'\n",
        "        blue_thr = 0.11\n",
        "\n",
        "    ## Select the red band\n",
        "    selectRedBand = bathyMask.select('B4')\n",
        "\n",
        "    ## Identify turbid areas first (pixel values higher than the threshold)\n",
        "    turbidMask = selectRedBand.gt(red_thr_inf)\n",
        "\n",
        "    ## Apply thresholds on red, green and blue bands\n",
        "    maskRed = selectRedBand.gt(red_thr_inf).And(selectRedBand.lt(red_thr_sup))\n",
        "    imageMaskRed = bathyMask.mask(maskRed)\n",
        "    maskGreen = imageMaskRed.select(green_band).lt(green_thr)\n",
        "    imageMaskGreen = imageMaskRed.mask(maskGreen)\n",
        "    maskBlue = imageMaskGreen.select(blue_band).lt(blue_thr) ##Shallow seagrass\n",
        "\n",
        "    ## Final mask (excluding seagrass/including turbid water)\n",
        "    turbidImage = bathyMask.mask(turbidMask) ## Turbidity\n",
        "    seagrassImage = bathyMask.mask(maskBlue).mask().Not() ## Shallow seagrass (inverse mask)\n",
        "    excludeSeagrass = turbidImage.updateMask(seagrassImage) ## Turbidity minus shallow seagrass\n",
        "    finalMaskImage = bathyMask.mask(excludeSeagrass)\n",
        "    finalMask = finalMaskImage.mask().Not()\n",
        "\n",
        "    ## Final Image\n",
        "    finalImage = bathyMask.updateMask(finalMask)\n",
        "    print('   Image masked...')\n",
        "\n",
        "    ###########################    WATER COLUMN CORRECTION    #########################    \n",
        "\n",
        "    ## Filter sand polygons by tile/area:\n",
        "    #sand = ee.FeatureCollection(sand_areas).flatten().filterBounds(imageGeometry)\n",
        "    sand = ee.FeatureCollection(sand_areas).filterBounds(imageGeometry)\n",
        "\n",
        "    ## Run the Depth-Invariant Index Function\n",
        "    imageDII = DII(finalImage, imageScale, sand)\n",
        "\n",
        "    print('   Depth-Invariant index applied...')\n",
        "\n",
        "    ###########################    SAMPLING    #########################\n",
        "    # Classes are:\n",
        "\n",
        "    # 0: Softbottom\n",
        "    # 1: Hardbottom\n",
        "    # 2: Seagrass\n",
        "    # 3: Sparse seagrass //if available\n",
        "\n",
        "    ## Filter ground points by tile geometry and display classes\n",
        "    filterPoints = ee.FeatureCollection(groundPoints).filterBounds(imageGeometry)\n",
        "\n",
        "    ## Select bands to sample. The B/G band is B2B3 in Sentinel-2 and Landsat-8, and B1B2 for Landsat-7/5\n",
        "    if 'Sentinel' in imageSat or 'Landsat8' in imageSat:\n",
        "        bandsClass = ['B1','B2', 'B3', 'B4','B2B3']\n",
        "        bg = ['B2B3']\n",
        "    else:\n",
        "        bandsClass = ['B1','B2', 'B3', 'B1B2']\n",
        "        bg = ['B1B2']\n",
        "\n",
        "    ## Add bands of interest to sample training points:\n",
        "    imageClassify = finalImage.addBands(imageDII.select(bg)).select(bandsClass)\n",
        "\n",
        "\n",
        "\n",
        "    ###########################    APPLY SMOOTHER    #########################\n",
        "    ## Define a boxcar or low-pass kernel (Used if want to smooth the image)\n",
        "    smooth = ee.Kernel.euclidean(**{\n",
        "        'radius': 1, \n",
        "        'units': 'pixels', \n",
        "        'normalize': True\n",
        "    })\n",
        "    \n",
        "    ## Apply smoother if set:\n",
        "    if 'smooth' in smoothStr:\n",
        "        imageClassify = imageClassify.convolve(smooth)\n",
        "    \n",
        "\n",
        "    ###########################    GET TRAINING AND VALIDATION DATA    #########################\n",
        "\n",
        "    ## Sample multi-spectral data using all ground points.\n",
        "    samplingData = imageClassify.sampleRegions(**{\n",
        "        'collection': filterPoints,\n",
        "        'properties': ['class'],\n",
        "        'scale': imageScale})\n",
        "\n",
        "    ## Add random numbers to each feature (from 0 to 1).\n",
        "    randomData = samplingData.randomColumn(\"random\",0)\n",
        "\n",
        "    ## Split ground data in training (~70%) and validation (~30%) points\n",
        "    trainingData = randomData.filter(ee.Filter.lt(\"random\",0.7))\n",
        "    validationData = randomData.filter(ee.Filter.gte(\"random\", 0.7))\n",
        "\n",
        "\n",
        "\n",
        "    ###########################    TRAIN MODELS AND CLASSIFY    #########################\n",
        "    print('   Training models and classifying...')\n",
        "\n",
        "    ## Train SVM classifier\n",
        "    SVM = ee.Classifier.libsvm(**{\n",
        "       'kernelType': 'RBF',\n",
        "       'gamma': 100,\n",
        "       'cost': 100\n",
        "    })\n",
        "    trainSVM = SVM.train(**{\n",
        "       'features': trainingData,\n",
        "       'classProperty': 'class',\n",
        "       'inputProperties': bandsClass\n",
        "    })\n",
        "\n",
        "\n",
        "    #### Classify the image using the trained classifier\n",
        "    classifiedSVM = imageClassify.classify(trainSVM)\n",
        "    \n",
        "    #########################  Clean classified image  ###########################\n",
        "    # seagrass_mask = ee.Image(\"users/lizcanosandoval/Seagrass/SeagrassMask_FL_100m\")\n",
        "    # classifiedSVM = classifiedSVM.updateMask(seagrass_mask) #For raster\n",
        "    aoi = regions.filter(ee.Filter.eq('name',regionName))\n",
        "    classifiedSVM = classifiedSVM.clip(aoi)\n",
        "\n",
        "\n",
        "    ###########################    TRAINING ACCURACIES    #########################\n",
        "    print('   Getting accuracies...')\n",
        "    ## Get a confusion matrix representing resubstitution accuracy.\n",
        "    ## {Resubstitution error is the error of a model on the training data.}\n",
        "    ## Axis 0 (first level) of the matrix correspond to the input classes (columns), \n",
        "    ## and axis 1 (second level) to the output classes (rows).\n",
        "    matrixTrainingSVM = trainSVM.confusionMatrix()\n",
        "\n",
        "\n",
        "    ###########################    VALIDATION ACCURACIES    #########################\n",
        "\n",
        "    ## Calculate accuracy using validation data\n",
        "    ## Classify the image using the trained classifier\n",
        "    validationSVM = validationData.classify(trainSVM)\n",
        "\n",
        "    ## Get a confusion matrix representing expected accuracy (Using validation points - 30%), where:\n",
        "    #  0: Softbottom\n",
        "    #  1: Hardbottom\n",
        "    #  2: Dense Seagrass\n",
        "    #  3: Spare Seagrass\n",
        "\n",
        "    ## Axis 0 (the rows) of the matrix correspond to the actual values, \n",
        "    ## and Axis 1 (the columns) to the predicted values.\n",
        "    errorMx = {'actual': 'class', 'predicted': 'classification'}\n",
        "    errorMatrixSVM = validationSVM.errorMatrix(**errorMx)\n",
        "\n",
        "\n",
        "    ###########################    USER/PRODUCER ACCURACIES    #########################\n",
        "\n",
        "    ## Estimate user and producer accuracies\n",
        "    producerAccuracySVM = errorMatrixSVM.producersAccuracy()\n",
        "\n",
        "    # USER\n",
        "    userAccuracySVM = errorMatrixSVM.consumersAccuracy()\n",
        "\n",
        "\n",
        "    ###########################    KAPPA COEFFICIENTS    #########################\n",
        "\n",
        "    # The Kappa Coefficient is generated from a statistical test to evaluate the accuracy \n",
        "    # of a classification. Kappa essentially evaluate how well the classification performed \n",
        "    # as compared to just randomly assigning values, i.e. did the classification do better \n",
        "    # than random. The Kappa Coefficient can range from -1 to 1. A value of 0 indicated that \n",
        "    # the classification is no better than a random classification. A negative number \n",
        "    # indicates the classification is significantly worse than random. A value close to 1 \n",
        "    # indicates that the classification is significantly better than random.\n",
        "    kappaSVM = errorMatrixSVM.kappa()\n",
        "\n",
        "\n",
        "\n",
        "    ###########################    EXPORT CLASSIFIED IMAGES    #########################\n",
        "\n",
        "    # Set the scale properly\n",
        "    scale = []\n",
        "    sat = []\n",
        "    method = ['SVM']\n",
        "    classifiedCollection = ee.ImageCollection([classifiedSVM])\n",
        "    classifiedList = classifiedCollection.toList(classifiedCollection.size())\n",
        "    classifiedSize = classifiedList.size().getInfo()\n",
        "    print('   Exporting classified images to EE Assets...')\n",
        "\n",
        "    for i in range(classifiedSize):\n",
        "\n",
        "        # Rename satellite\n",
        "        if 'Sentinel' in imageSat:\n",
        "            sat = 'Sentinel'\n",
        "        else:\n",
        "            sat = 'Landsat'\n",
        "\n",
        "        ## Select image\n",
        "        image = ee.Image(classifiedList.get(i))\n",
        "\n",
        "        # set some properties for export\n",
        "        output = image.set({'satellite': imageSat,\n",
        "                       'tile_id': str(imageTile),\n",
        "                       'file_id': imageID,                                               \n",
        "                       'date': imageDate,\n",
        "                       'year': imageDate[0:4],\n",
        "                       'classifier': method[i],\n",
        "                       'generator': 'Lizcano-Sandoval',\n",
        "                            })\n",
        "\n",
        "        # define YOUR assetID. (This do not create folders, you need to create them manually)\n",
        "        assetID = 'users/lizcanosandoval/Seagrass/'+sat+'/Venezuela/'+exportFolder+'/' ##This goes to an ImageCollection folder\n",
        "        fileName = imageID+smoothStr+ method[i]\n",
        "        path = assetID + fileName\n",
        "\n",
        "        ## Batch Export to Assets\n",
        "        ee.batch.Export.image.toAsset(\\\n",
        "            image = ee.Image(output),                                                    \n",
        "            description = method[i] +smoothStr+ imageID,\n",
        "            assetId = path,\n",
        "            region = imageGeometry.buffer(10),                                      \n",
        "            maxPixels = 1e13,\n",
        "            scale = imageScale).start()\n",
        "        print('   Classified Image '+str(i+1)+': '+imageID +smoothStr+ method[i]+' submitted...')\n",
        "    print('   Classified images submitted!')\n",
        "\n",
        "\n",
        "\n",
        "    ###########################    SAVE MATRICES TO WORKING DIRECTORY    #########################\n",
        "    print('   Saving matrices to working directory...')\n",
        "    # Extract values from each matrix\n",
        "    SVM_trainingMatrix = matrixTrainingSVM.array().getInfo()\n",
        "    SVM_trainingAccuracy = matrixTrainingSVM.accuracy().getInfo()\n",
        "    SVM_errorMatrix = errorMatrixSVM.array().getInfo()\n",
        "    SVM_errorAccuracy = errorMatrixSVM.accuracy().getInfo()\n",
        "    SVM_producerAccuracy = producerAccuracySVM.getInfo()\n",
        "    SVM_userAccuracy = userAccuracySVM.getInfo()\n",
        "    SVM_kappa = kappaSVM.getInfo()\n",
        "\n",
        "\n",
        "    ## Convert matrices to pandas dataframes:\n",
        "    #Training Matrices\n",
        "    rowIndex = {0:'Sb', 1:'Hb', 2:'Dn', 3:'Sp'}\n",
        "    TM_SVM = pd.DataFrame(SVM_trainingMatrix).rename(columns=rowIndex, index=rowIndex)\n",
        "    TM_concat = pd.concat([TM_SVM], keys=['SVM'])\n",
        "\n",
        "    #Training Accuracies\n",
        "    TA_SVM = pd.Series(SVM_trainingAccuracy)\n",
        "    TA_concat = pd.DataFrame(pd.concat([TA_SVM],ignore_index=True), columns=(['Tr_Accuracy']))\\\n",
        "                    .rename({0:'SVM'})\n",
        "\n",
        "    #Validation-Error Matrices\n",
        "    VM_SVM = pd.DataFrame(SVM_errorMatrix).rename(columns=rowIndex, index=rowIndex)\n",
        "    VM_concat = pd.concat([VM_SVM], keys=['SVM'])\n",
        "\n",
        "    #Validation Accuracies\n",
        "    VA_SVM = pd.Series(SVM_errorAccuracy)\n",
        "    VA_concat = pd.DataFrame(pd.concat([VA_SVM],ignore_index=True), columns=(['Va_Accuracy']))\\\n",
        "                    .rename({0:'SVM'})\n",
        "\n",
        "    #Producer-User Accuracies\n",
        "    ## Create a pandas dataframe with producer and user accuracies:\n",
        "    dfPA_SVM = pd.DataFrame(producerAccuracySVM.getInfo(), columns=['Producer'])\n",
        "    dfUA_SVM = pd.DataFrame(userAccuracySVM.getInfo()).transpose()\n",
        "\n",
        "    PU_SVM = pd.concat([dfPA_SVM, dfUA_SVM.rename(columns={0:'User'})], axis=1).rename(index=rowIndex)\n",
        "    PU_concat = pd.concat([PU_SVM], keys=['SVM'])\n",
        "\n",
        "    # Kappa coefficients\n",
        "    Kp_SVM = pd.Series(SVM_kappa)\n",
        "    Kp_concat = pd.DataFrame(pd.concat([Kp_SVM],ignore_index=True), columns=(['Kappa']))\\\n",
        "                    .rename({0:'SVM'})\n",
        "\n",
        "    # Extract the number of training and validation points per class:\n",
        "    trainingInfo = trainingData.aggregate_histogram('class').getInfo()\n",
        "    validationInfo = validationData.aggregate_histogram('class').getInfo()\n",
        "\n",
        "    traSeries = pd.Series(trainingInfo)\n",
        "    valSeries = pd.Series(validationInfo)\n",
        "\n",
        "    Points_concat = pd.DataFrame(pd.concat([traSeries, valSeries],ignore_index=True,axis=1))\\\n",
        "                    .rename(columns={0:'TraPoints',1:'ValPoints'}).rename({'0':'Sb','1':'Hb','2':'Dn'},axis='index')\n",
        "    \n",
        "    # Organize each matrix in separate excel sheets\n",
        "    excelName = 'Mrx'+ smoothStr + imageID +'.xlsx'\n",
        "    excel = pd.ExcelWriter(excelName, engine='xlsxwriter')\n",
        "\n",
        "    Points_concat.to_excel(excel, sheet_name='Points', index=True, startrow=0)\n",
        "    TM_concat.to_excel(excel, sheet_name='TrMrx', index=True, startrow=0)\n",
        "    TA_concat.to_excel(excel, sheet_name='TrAcc', index=True, startrow=0)\n",
        "    VM_concat.to_excel(excel, sheet_name='VaMrx', index=True, startrow=0)\n",
        "    VA_concat.to_excel(excel, sheet_name='VaAcc', index=True, startrow=0)\n",
        "    PU_concat.to_excel(excel, sheet_name='PU-Mrx', index=True, startrow=0)\n",
        "    Kp_concat.to_excel(excel, sheet_name='Kappa', index=True, startrow=0)\n",
        "\n",
        "    # Save matrices as .xlsx file:\n",
        "    excel.save()\n",
        "    print('   Saved Matrices of '+imageID)\n",
        "\n",
        "print('ALL IMAGES HAVE BEEN CLASSIFIED!')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initiating...\n",
            "Preparing image 20200522T150731_20200522T150726_T19PEN\n",
            "   Image masked...\n",
            "   Depth-Invariant index applied...\n",
            "   Training models and classifying...\n",
            "   Getting accuracies...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "EEException",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mHttpError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ee/data.py\u001b[0m in \u001b[0;36m_execute_cloud_call\u001b[0;34m(call, num_retries)\u001b[0m\n\u001b[1;32m    333\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 334\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_retries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_retries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    335\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mgoogleapiclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHttpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/googleapiclient/_helpers.py\u001b[0m in \u001b[0;36mpositional_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    133\u001b[0m                     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/googleapiclient/http.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, http, num_retries)\u001b[0m\n\u001b[1;32m    914\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mHttpError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muri\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muri\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpostproc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mHttpError\u001b[0m: <HttpError 400 when requesting https://earthengine.googleapis.com/v1alpha/projects/earthengine-legacy/value:compute?prettyPrint=false&alt=json returned \"No valid training data were found.\". Details: \"No valid training data were found.\">",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mEEException\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-b15006d922d4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'print(\\'Initiating...\\')\\n\\n## Initiate loop:\\nfor i in range(len(imageList)):\\n    imageID = imageList[i]\\n    \\n    print(\\'Preparing image \\'+imageID)\\n    \\n    #############################   Prepare image metadata  ##################################\\n\\n    ## If the image source is your asset, then define the folder where the satellite image is:\\n    if \\'assets\\'== imageSource:\\n        ## Load BOA image from assets:\\n        if \\'Sentinel\\' in satellite:\\n            imageTarget = ee.Image(\"users/lizcanosandoval/BOA/Sentinel/\"+boaFolder+\\'/\\'+imageID)\\n        elif \\'Landsat\\' in satellite:\\n            imageTarget = ee.Image(\"users/lizcanosandoval/BOA/Landsat/\"+boaFolder+\\'/\\'+imageID)\\n\\n    ## If the image source is an EE collection, then define the satellite collection:\\n    if \\'ee\\'== imageSource:\\n        ## Load BOA image collection from assets:\\n        if \\'Sentinel\\' in satellite:\\n            image = ee.Image(\"COPERNICUS/S2_SR/\"+imageID)\\n        elif \\'Landsat8\\' == satellite:\\n            image = ee.Image(\"LANDSAT/LC08/C01/T1_SR/\"+imageID)\\n        elif \\'Landsat7\\' == satellite:\\n            image = ee.Image(\"LANDSAT/LE07/C01/T1_SR/\"+imageID)\\n        elif \\'Landsat5\\' == satellite:\\n            image = ee.Image(\"LANDSAT/LT05/C01/T1_SR/\"+imageID)\\n\\n    ## Get image metadata:\\n ...\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2115\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2116\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2117\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2118\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<decorator-gen-53>\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1191\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1193\u001b[0;31m             \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1194\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1195\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ee/computedobject.py\u001b[0m in \u001b[0;36mgetInfo\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     96\u001b[0m       \u001b[0mThe\u001b[0m \u001b[0mobject\u001b[0m \u001b[0mcan\u001b[0m \u001b[0mevaluate\u001b[0m \u001b[0mto\u001b[0m \u001b[0manything\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     \"\"\"\n\u001b[0;32m---> 98\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomputeValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ee/data.py\u001b[0m in \u001b[0;36mcomputeValue\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m    674\u001b[0m           \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'expression'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mserializer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfor_cloud_api\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m           \u001b[0mproject\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_get_projects_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m           prettyPrint=False))['result']\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ee/data.py\u001b[0m in \u001b[0;36m_execute_cloud_call\u001b[0;34m(call, num_retries)\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_retries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_retries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mgoogleapiclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHttpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 336\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0m_translate_cloud_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mEEException\u001b[0m: No valid training data were found."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XUIxL8rV7mvz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}